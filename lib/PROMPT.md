I’m looking to build a serverless image-inference pipeline in AWS using Pulumi (Python). Think of it as a simple, reliable flow: images come in, we pre-process them, run inference with a pre-trained model, and then save the results and make them easy to query. Please generate production-ready Pulumi code in Python that stands up everything end-to-end in us-east-1, along with brief inline comments so it’s easy to follow.

Assume the basics are in place on my side (Pulumi CLI configured, Python 3.8+ available, AWS CLI authenticated with permissions). I want you to wire the resources together so the experience feels cohesive: an S3 bucket where uploads land (with versioning turned on), a Lambda that handles lightweight image preprocessing, another Lambda that performs model inference via a Lambda Layer that contains the pre-trained model and its dependencies, and SQS to decouple the steps so spikes don’t hurt us. Persist final results in DynamoDB with a sensible primary key and access patterns that make status/result lookups cheap. Expose simple REST endpoints via API Gateway so I can upload, check status, and retrieve results. Give each function the least privilege it needs through custom IAM roles and policies, and make sure the plumbing is correct (S3 → SQS → Lambdas → DynamoDB, plus API → Lambdas where appropriate). Add CloudWatch alarms around the critical pieces so we’ll notice processing errors, dead-letter activity, or throttling before users do.

A few quality-of-life details I care about: make the code organized and composable (helper functions or small classes are fine), name resources in a predictable way, and surface the important outputs at the end (API base URL, S3 upload URL/prefix, DynamoDB table name, and any queue or function ARNs that will matter for ops). For the API, keep the paths straightforward (e.g., POST /images to submit, GET /images/{id} to check status and read results). For error handling, include DLQs or retry policies where they make sense, and add logging that’s actually useful in CloudWatch (think request ids and concise error summaries). If something needs a reasonable default (timeouts, memory, batch sizes), choose sane values and note them briefly in comments so I know what to tune later.

When you return the answer, include the Pulumi program files I’ll need in one place—main code plus any small support modules and a minimal __main__ entrypoint—so I can run `pulumi up` without spelunking. Close with a short explanation of how messages flow through the system and how the design meets the “accept upload → process async → store results → status via API” promise. If there’s anything I should pre-create (like a model layer artifact) or an assumption you’re making (image size limits, memory for inference, cold start tradeoffs), call it out plainly so I can fill in the gaps.