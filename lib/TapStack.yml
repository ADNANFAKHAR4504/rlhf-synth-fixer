AWSTemplateFormatVersion: '2010-09-09'
Description: 'Expert-level CloudFormation template for secure infrastructure deployment in us-east-1'

# Parameters with default values for automated pipeline deployment
Parameters:
  ProjectName:
    Type: String
    Default: 'secureorg'
    Description: 'Project name used in resource naming convention'
    AllowedPattern: '^[a-z][a-z0-9-]*$'
    ConstraintDescription: 'Project name must start with lowercase letter and contain only lowercase letters, numbers, and hyphens'
    MinLength: 3
    MaxLength: 20
    
  Environment:
    Type: String
    Default: 'prod'
    AllowedValues:
      - 'dev'
      - 'staging'
      - 'prod'
    Description: 'Environment for deployment (dev, staging, prod)'
    
  LambdaFunctionName:
    Type: String
    Default: 'secure-data-processor'
    Description: 'Name for the Lambda function'
    AllowedPattern: '^[a-zA-Z][a-zA-Z0-9-]*$'
    ConstraintDescription: 'Function name must start with a letter and contain only letters, numbers, and hyphens'
    MinLength: 3
    MaxLength: 30

Resources:
  # ===========================================
  # IAM ROLE FOR PASSWORD POLICY ENFORCEMENT
  # Custom Lambda function to enforce password policy (workaround for AWS::IAM::AccountPasswordPolicy not available in us-east-1)
  # ===========================================
  PasswordPolicyLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${ProjectName}-${Environment}-password-policy-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: IAMPasswordPolicyAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 'iam:UpdateAccountPasswordPolicy'
                  - 'iam:GetAccountPasswordPolicy'
                Resource: '*'

  # Lambda function to set account password policy
  PasswordPolicyLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-${Environment}-password-policy-enforcer'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt PasswordPolicyLambdaRole.Arn
      Timeout: 60
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse
          
          def lambda_handler(event, context):
              try:
                  iam = boto3.client('iam')
                  
                  if event['RequestType'] == 'Create' or event['RequestType'] == 'Update':
                      # Set account password policy with required security parameters
                      iam.update_account_password_policy(
                          MinimumPasswordLength=12,
                          RequireSymbols=True,
                          RequireNumbers=True,
                          RequireUppercaseCharacters=True,
                          RequireLowercaseCharacters=True,
                          AllowUsersToChangePassword=True,
                          MaxPasswordAge=90,
                          PasswordReusePrevention=12,
                          HardExpiry=True
                      )
                      print("Password policy updated successfully")
                  
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                  
              except Exception as e:
                  print(f"Error: {str(e)}")
                  cfnresponse.send(event, context, cfnresponse.FAILED, {})

  # Custom resource to trigger password policy enforcement
  PasswordPolicyCustomResource:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt PasswordPolicyLambda.Arn

  # ===========================================
  # S3 BUCKETS
  # Multiple private S3 buckets with security best practices
  # ===========================================
  
  # Primary Data Bucket
  PrimaryDataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${ProjectName}-${Environment}-s3bucket-primary'
      # Block all public access by default
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      # Enable versioning for data protection
      VersioningConfiguration:
        Status: Enabled
      # Server-side encryption with S3 managed keys
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
            BucketKeyEnabled: true
      # Lifecycle configuration to manage storage costs (fixed syntax)
      LifecycleConfiguration:
        Rules:
          - Id: 'TransitionToIA'
            Status: Enabled
            Transitions:
              - TransitionInDays: 30
                StorageClass: STANDARD_IA
          - Id: 'TransitionToGlacier'
            Status: Enabled
            Transitions:
              - TransitionInDays: 90
                StorageClass: GLACIER

  # Secondary Backup Bucket
  BackupDataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${ProjectName}-${Environment}-s3bucket-backup'
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
            BucketKeyEnabled: true

  # Logs Bucket for audit trails
  LogsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${ProjectName}-${Environment}-s3bucket-logs'
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
            BucketKeyEnabled: true
      # Extended retention for compliance (fixed syntax)
      LifecycleConfiguration:
        Rules:
          - Id: 'LogsRetention'
            Status: Enabled
            Transitions:
              - TransitionInDays: 365
                StorageClass: GLACIER
          - Id: 'LogsDeletion'
            Status: Enabled
            ExpirationInDays: 2555  # 7 years retention

  # ===========================================
  # IAM ROLE FOR LAMBDA FUNCTION
  # Secure execution role with minimal required permissions
  # ===========================================
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${ProjectName}-${Environment}-lambda-execution-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      # Managed policy for basic Lambda execution
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      # Custom inline policy for S3 access (fixed ARN references)
      Policies:
        - PolicyName: S3AccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                  - 's3:PutObject'
                  - 's3:DeleteObject'
                Resource:
                  - !Sub 'arn:aws:s3:::${PrimaryDataBucket}/*'
                  - !Sub 'arn:aws:s3:::${BackupDataBucket}/*'
              - Effect: Allow
                Action:
                  - 's3:ListBucket'
                Resource:
                  - !GetAtt PrimaryDataBucket.Arn
                  - !GetAtt BackupDataBucket.Arn
              - Effect: Allow
                Action:
                  - 's3:PutObject'
                Resource:
                  - !Sub 'arn:aws:s3:::${LogsBucket}/*'

  # ===========================================
  # LAMBDA FUNCTION
  # Secure data processor with environment variables protection
  # ===========================================
  DataProcessorLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-${Environment}-${LambdaFunctionName}'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Timeout: 300
      MemorySize: 256
      # Environment variables for configuration (non-sensitive only)
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment
          PROJECT_NAME: !Ref ProjectName
          PRIMARY_BUCKET: !Ref PrimaryDataBucket
          BACKUP_BUCKET: !Ref BackupDataBucket
          LOGS_BUCKET: !Ref LogsBucket
          # Note: AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are automatically
          # provided by the Lambda execution environment and should NOT be set here
      # Inline code that demonstrates secure logging practices
      Code:
        ZipFile: |
          import json
          import boto3
          import logging
          import os
          from datetime import datetime
          import re
          
          # Configure logging to filter sensitive information
          class SensitiveInfoFilter(logging.Filter):
              """Custom filter to prevent logging of sensitive AWS credentials"""
              
              SENSITIVE_PATTERNS = [
                  r'AWS_ACCESS_KEY_ID',
                  r'AWS_SECRET_ACCESS_KEY',
                  r'AWS_SESSION_TOKEN',
                  r'AKIA[0-9A-Z]{16}',  # AWS Access Key pattern
                  r'[A-Za-z0-9/+=]{40}',  # AWS Secret Key pattern (basic)
              ]
              
              def filter(self, record):
                  # Check if log message contains sensitive information
                  message = record.getMessage()
                  for pattern in self.SENSITIVE_PATTERNS:
                      if re.search(pattern, message, re.IGNORECASE):
                          record.msg = "[REDACTED - Sensitive AWS credential detected]"
                          record.args = ()
                          break
                  return True
          
          # Set up logger with sensitive info filter
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          
          # Add the filter to prevent sensitive data logging
          for handler in logger.handlers:
              handler.addFilter(SensitiveInfoFilter())
          
          def lambda_handler(event, context):
              """
              Secure Lambda function that processes S3 events without exposing credentials
              """
              try:
                  # Log the event (safe to log as it doesn't contain credentials)
                  logger.info(f"Processing event: {json.dumps(event, default=str)}")
                  
                  # Get environment variables (safe to log these specific ones)
                  environment = os.environ.get('ENVIRONMENT', 'unknown')
                  project_name = os.environ.get('PROJECT_NAME', 'unknown')
                  
                  logger.info(f"Running in environment: {environment}, project: {project_name}")
                  
                  # Initialize S3 client using IAM role (credentials handled automatically)
                  s3_client = boto3.client('s3')
                  
                  # Process S3 events securely
                  if 'Records' in event:
                      for record in event['Records']:
                          if record.get('eventSource') == 'aws:s3':
                              bucket_name = record['s3']['bucket']['name']
                              object_key = record['s3']['object']['key']
                              
                              logger.info(f"Processing object: {object_key} from bucket: {bucket_name}")
                              
                              # Secure data processing logic here
                              # Example: Copy to backup bucket
                              backup_bucket = os.environ.get('BACKUP_BUCKET')
                              if backup_bucket:
                                  copy_source = {'Bucket': bucket_name, 'Key': object_key}
                                  s3_client.copy_object(
                                      CopySource=copy_source,
                                      Bucket=backup_bucket,
                                      Key=f"backup-{datetime.utcnow().isoformat()}-{object_key}"
                                  )
                                  logger.info(f"Successfully backed up {object_key}")
                  
                  # Demonstrate secure environment variable handling
                  # NEVER log AWS credentials directly
                  env_vars = dict(os.environ)
                  safe_env_vars = {k: v for k, v in env_vars.items() 
                                  if not k.startswith('AWS_') or k in ['AWS_REGION', 'AWS_DEFAULT_REGION']}
                  
                  logger.info(f"Safe environment variables: {json.dumps(safe_env_vars)}")
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'message': 'Data processed successfully',
                          'environment': environment,
                          'timestamp': datetime.utcnow().isoformat()
                      })
                  }
                  
              except Exception as e:
                  logger.error(f"Error processing data: {str(e)}")
                  return {
                      'statusCode': 500,
                      'body': json.dumps({
                          'error': 'Internal server error',
                          'timestamp': datetime.utcnow().isoformat()
                      })
                  }

  # ===========================================
  # S3 BUCKET NOTIFICATION CONFIGURATION
  # Configure S3 to trigger Lambda on object creation
  # ===========================================
  S3BucketNotification:
    Type: AWS::S3::Bucket
    DependsOn: S3InvokeLambdaPermission
    Properties:
      BucketName: !Sub '${ProjectName}-${Environment}-s3bucket-primary-with-notifications'
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
            BucketKeyEnabled: true
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: 's3:ObjectCreated:*'
            Function: !GetAtt DataProcessorLambda.Arn

  # ===========================================
  # S3 BUCKET PERMISSIONS FOR LAMBDA
  # Allow Lambda to be invoked by S3 bucket notifications (fixed ARN with SourceAccount)
  # ===========================================
  S3InvokeLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref DataProcessorLambda
      Action: lambda:InvokeFunction
      Principal: s3.amazonaws.com
      SourceArn: !GetAtt PrimaryDataBucket.Arn
      SourceAccount: !Ref 'AWS::AccountId'

  # ===========================================
  # CLOUDWATCH LOG GROUP
  # Secure log retention for Lambda function
  # ===========================================
  LambdaLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/lambda/${ProjectName}-${Environment}-${LambdaFunctionName}'
      RetentionInDays: 30

  # ===========================================
  # IAM POLICY FOR ENHANCED SECURITY
  # Additional security policy for the organization (fixed ARNs)
  # ===========================================
  OrganizationSecurityPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      ManagedPolicyName: !Sub '${ProjectName}-${Environment}-security-policy'
      Description: 'Organization security policy enforcing best practices'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          # Deny unencrypted S3 uploads (fixed ARN references)
          - Sid: DenyUnencryptedS3Uploads
            Effect: Deny
            Action: 's3:PutObject'
            Resource: 
              - !Sub 'arn:aws:s3:::${PrimaryDataBucket}/*'
              - !Sub 'arn:aws:s3:::${BackupDataBucket}/*'
              - !Sub 'arn:aws:s3:::${LogsBucket}/*'
            Condition:
              StringNotEquals:
                's3:x-amz-server-side-encryption': 'AES256'
          # Enforce HTTPS for S3 operations (fixed ARN references)
          - Sid: DenyInsecureS3Operations
            Effect: Deny
            Action: 's3:*'
            Resource:
              - !GetAtt PrimaryDataBucket.Arn
              - !Sub 'arn:aws:s3:::${PrimaryDataBucket}/*'
              - !GetAtt BackupDataBucket.Arn
              - !Sub 'arn:aws:s3:::${BackupDataBucket}/*'
              - !GetAtt LogsBucket.Arn
              - !Sub 'arn:aws:s3:::${LogsBucket}/*'
            Condition:
              Bool:
                'aws:SecureTransport': 'false'
          # Restrict Lambda function modifications (using valid condition)
          - Sid: RestrictLambdaModification
            Effect: Deny
            Action:
              - 'lambda:UpdateFunctionCode'
              - 'lambda:UpdateFunctionConfiguration'
              - 'lambda:DeleteFunction'
            Resource: !GetAtt DataProcessorLambda.Arn
            Condition:
              StringNotEquals:
                'aws:PrincipalTag/Department': 'SecurityTeam'

# ===========================================
# OUTPUTS
# Export important resource identifiers
# ===========================================
Outputs:
  PrimaryBucketName:
    Description: 'Name of the primary S3 bucket'
    Value: !Ref PrimaryDataBucket
    Export:
      Name: !Sub '${AWS::StackName}-PrimaryBucket'
      
  BackupBucketName:
    Description: 'Name of the backup S3 bucket'
    Value: !Ref BackupDataBucket
    Export:
      Name: !Sub '${AWS::StackName}-BackupBucket'
      
  LogsBucketName:
    Description: 'Name of the logs S3 bucket'
    Value: !Ref LogsBucket
    Export:
      Name: !Sub '${AWS::StackName}-LogsBucket'
      
  LambdaFunctionArn:
    Description: 'ARN of the data processor Lambda function'
    Value: !GetAtt DataProcessorLambda.Arn
    Export:
      Name: !Sub '${AWS::StackName}-LambdaFunction'
      
  LambdaExecutionRoleArn:
    Description: 'ARN of the Lambda execution role'
    Value: !GetAtt LambdaExecutionRole.Arn
    Export:
      Name: !Sub '${AWS::StackName}-LambdaRole'
      
  SecurityPolicyArn:
    Description: 'ARN of the organization security policy'
    Value: !Ref OrganizationSecurityPolicy
    Export:
      Name: !Sub '${AWS::StackName}-SecurityPolicy'