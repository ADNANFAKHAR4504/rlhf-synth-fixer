AWSTemplateFormatVersion: '2010-09-09'
Description: 'Serverless application with Lambda, API Gateway, DynamoDB, S3, and monitoring - Multi-environment support'

Parameters:
  Environment:
    Type: String
    AllowedValues:
      - dev
      - stage
      - prod
    Default: dev
    Description: 'Environment type (dev, stage, prod)'

  EnvironmentSuffix:
    Type: String
    Default: dev
    Description: 'Unique environment suffix for resource naming (e.g., dev, pr1195, prod)'
    AllowedPattern: '^[a-zA-Z0-9]+$'
    ConstraintDescription: 'Must contain only alphanumeric characters'

  LogLevel:
    Type: String
    AllowedValues:
      - INFO
      - WARN
      - ERROR
      - DEBUG
    Default: INFO
    Description: 'Log level for Lambda function'

  EnableVPCRestrictions:
    Type: String
    Default: 'false'
    AllowedValues:
      - 'true'
      - 'false'
    Description: 'Enable VPC-only access restrictions (recommended for production)'

  VPCEndpointId:
    Type: String
    Default: ''
    Description: 'VPC Endpoint ID for API Gateway (required if EnableVPCRestrictions is true)'

Conditions:
  IsProduction: !Equals [!Ref Environment, prod]
  EnableVPCAccess: !Equals [!Ref EnableVPCRestrictions, 'true']
  HasVPCEndpoint: !And
    - !Condition EnableVPCAccess
    - !Not [!Equals [!Ref VPCEndpointId, '']]

Resources:
  # S3 Bucket for Lambda code and application data
  ApplicationBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::StackName}-app-bucket-${EnvironmentSuffix}'
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldVersions
            Status: Enabled
            NoncurrentVersionExpirationInDays: 30
          - Id: TransitionToIA
            Status: Enabled
            Transitions:
              - TransitionInDays: 30
                StorageClass: STANDARD_IA
              - TransitionInDays: 90
                StorageClass: GLACIER
          - Id: DeleteOldData
            Status: Enabled
            ExpirationInDays: 365
            Prefix: logs/
          - Id: AbortIncompleteMultipartUploads
            Status: Enabled
            AbortIncompleteMultipartUpload:
              DaysAfterInitiation: 7
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: EnvironmentSuffix
          Value: !Ref EnvironmentSuffix
        - Key: Stack
          Value: !Ref AWS::StackName

  # S3 Bucket Policy with VPC restrictions for production
  ApplicationBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Condition: IsProduction
    Properties:
      Bucket: !Ref ApplicationBucket
      PolicyDocument:
        Statement:
          - Sid: DenyInsecureConnections
            Effect: Deny
            Principal: '*'
            Action: 's3:*'
            Resource:
              - !GetAtt ApplicationBucket.Arn
              - !Sub '${ApplicationBucket.Arn}/*'
            Condition:
              Bool:
                'aws:SecureTransport': 'false'
          - Sid: VPCOnlyAccess
            Effect: Deny
            Principal: '*'
            Action: 's3:*'
            Resource:
              - !GetAtt ApplicationBucket.Arn
              - !Sub '${ApplicationBucket.Arn}/*'
            Condition:
              StringNotEquals:
                'aws:SourceVpce':
                  !If [HasVPCEndpoint, !Ref VPCEndpointId, !Ref AWS::NoValue]

  # IAM Role for Lambda
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: DynamoDBAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:PutItem
                  - dynamodb:GetItem
                  - dynamodb:UpdateItem
                  - dynamodb:DeleteItem
                  - dynamodb:Query
                  - dynamodb:Scan
                Resource:
                  - !GetAtt DataTable.Arn
                  - !Sub '${DataTable.Arn}/index/*'
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                Resource: !Sub '${ApplicationBucket.Arn}/*'
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource: !GetAtt ApplicationBucket.Arn
        - PolicyName: CloudWatchLogs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub 'arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/${AWS::StackName}-data-processor-${EnvironmentSuffix}:*'
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: EnvironmentSuffix
          Value: !Ref EnvironmentSuffix

  # CloudWatch Log Group
  LambdaLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/lambda/${AWS::StackName}-data-processor-${EnvironmentSuffix}'
      RetentionInDays: !If [IsProduction, 30, 14]

  # Lambda Function
  DataProcessorFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${AWS::StackName}-data-processor-${EnvironmentSuffix}'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          import logging
          from datetime import datetime
          import uuid

          # Configure logging
          log_level = os.environ.get('LOG_LEVEL', 'INFO')
          logger = logging.getLogger()
          logger.setLevel(getattr(logging, log_level))

          # Initialize AWS clients
          dynamodb = boto3.resource('dynamodb', region_name=os.environ.get('REGION'))
          s3 = boto3.client('s3', region_name=os.environ.get('REGION'))

          table_name = os.environ.get('TABLE_NAME')
          bucket_name = os.environ.get('BUCKET_NAME')
          table = dynamodb.Table(table_name)

          def lambda_handler(event, context):
              try:
                  logger.info(f"Processing event: {json.dumps(event)}")
                  
                  # Parse request body
                  if 'body' in event:
                      body = json.loads(event['body']) if isinstance(event['body'], str) else event['body']
                  else:
                      body = event
                  
                  # Create item for DynamoDB
                  item_id = str(uuid.uuid4())
                  item = {
                      'id': item_id,
                      'timestamp': datetime.utcnow().isoformat(),
                      'data': body,
                      'environment': os.environ.get('ENVIRONMENT', 'dev'),
                      'environment_suffix': os.environ.get('ENVIRONMENT_SUFFIX', 'dev'),
                      'request_id': context.request_id if context else 'local-test'
                  }
                  
                  # Store in DynamoDB
                  table.put_item(Item=item)
                  logger.info(f"Successfully stored item with id: {item['id']}")
                  
                  # Store backup in S3 if enabled
                  if os.environ.get('ENABLE_S3_BACKUP', 'false') == 'true':
                      s3_key = f"data/{datetime.utcnow().strftime('%Y/%m/%d')}/{item_id}.json"
                      s3.put_object(
                          Bucket=bucket_name,
                          Key=s3_key,
                          Body=json.dumps(item),
                          ContentType='application/json',
                          ServerSideEncryption='AES256'
                      )
                      logger.info(f"Backed up to S3: {s3_key}")
                  
                  return {
                      'statusCode': 200,
                      'headers': {
                          'Content-Type': 'application/json',
                          'X-Environment': os.environ.get('ENVIRONMENT', 'dev'),
                          'X-Request-Id': context.request_id if context else 'local-test'
                      },
                      'body': json.dumps({
                          'message': 'Data processed successfully',
                          'id': item['id'],
                          'timestamp': item['timestamp']
                      })
                  }
                  
              except Exception as e:
                  logger.error(f"Error processing data: {str(e)}", exc_info=True)
                  return {
                      'statusCode': 500,
                      'headers': {
                          'Content-Type': 'application/json'
                      },
                      'body': json.dumps({
                          'error': 'Internal server error',
                          'message': str(e) if os.environ.get('ENVIRONMENT') != 'prod' else 'An error occurred'
                      })
                  }
      Environment:
        Variables:
          ENVIRONMENT: !Ref Environment
          ENVIRONMENT_SUFFIX: !Ref EnvironmentSuffix
          LOG_LEVEL: !Ref LogLevel
          TABLE_NAME: !Ref DataTable
          BUCKET_NAME: !Ref ApplicationBucket
          REGION: !Ref AWS::Region
          ENABLE_S3_BACKUP: !If [IsProduction, 'true', 'false']
      Timeout: 30
      MemorySize: !If [IsProduction, 256, 128]
      ReservedConcurrentExecutions: !If [IsProduction, 100, 10]
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: EnvironmentSuffix
          Value: !Ref EnvironmentSuffix

  # Lambda Permission for API Gateway
  LambdaApiGatewayPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref DataProcessorFunction
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${DataApi}/*/*'

  # API Gateway REST API
  DataApi:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: !Sub '${AWS::StackName}-api-${EnvironmentSuffix}'
      Description: 'REST API for data processing'
      EndpointConfiguration:
        Types:
          - REGIONAL
        VpcEndpointIds: !If
          - HasVPCEndpoint
          - [!Ref VPCEndpointId]
          - !Ref AWS::NoValue
      Policy: !If
        - EnableVPCAccess
        - !Sub |
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Deny",
                "Principal": "*",
                "Action": "execute-api:Invoke",
                "Resource": "execute-api:/*",
                "Condition": {
                  "StringNotEquals": {
                    "aws:SourceVpce": "${VPCEndpointId}"
                  }
                }
              }
            ]
          }
        - !Ref AWS::NoValue
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: EnvironmentSuffix
          Value: !Ref EnvironmentSuffix

  # API Gateway Resource
  DataResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref DataApi
      ParentId: !GetAtt DataApi.RootResourceId
      PathPart: data

  # API Gateway Method
  DataMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref DataApi
      ResourceId: !Ref DataResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${DataProcessorFunction.Arn}/invocations'
      MethodResponses:
        - StatusCode: 200
          ResponseModels:
            application/json: Empty
        - StatusCode: 500
          ResponseModels:
            application/json: Empty

  # API Gateway GET Method for health check
  HealthResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref DataApi
      ParentId: !GetAtt DataApi.RootResourceId
      PathPart: health

  HealthMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref DataApi
      ResourceId: !Ref HealthResource
      HttpMethod: GET
      AuthorizationType: NONE
      Integration:
        Type: MOCK
        IntegrationResponses:
          - StatusCode: 200
            ResponseTemplates:
              application/json: '{"status": "healthy", "environment": "${stageVariables.environment}"}'
      MethodResponses:
        - StatusCode: 200
          ResponseModels:
            application/json: Empty

  # API Gateway Deployment
  ApiDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn:
      - DataMethod
      - HealthMethod
    Properties:
      RestApiId: !Ref DataApi
      StageName: !Ref EnvironmentSuffix
      StageDescription:
        Description: !Sub 'Deployment stage for ${EnvironmentSuffix}'
        Variables:
          environment: !Ref Environment
          environment_suffix: !Ref EnvironmentSuffix

  # DynamoDB Table
  DataTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub '${AWS::StackName}-data-table-${EnvironmentSuffix}'
      BillingMode: !If [IsProduction, PROVISIONED, PAY_PER_REQUEST]
      AttributeDefinitions:
        - AttributeName: id
          AttributeType: S
        - AttributeName: timestamp
          AttributeType: S
      KeySchema:
        - AttributeName: id
          KeyType: HASH
      GlobalSecondaryIndexes:
        - IndexName: timestamp-index
          KeySchema:
            - AttributeName: timestamp
              KeyType: HASH
          Projection:
            ProjectionType: ALL
          ProvisionedThroughput: !If
            - IsProduction
            - ReadCapacityUnits: 5
              WriteCapacityUnits: 5
            - !Ref AWS::NoValue
      ProvisionedThroughput: !If
        - IsProduction
        - ReadCapacityUnits: 5
          WriteCapacityUnits: 5
        - !Ref AWS::NoValue
      PointInTimeRecoverySpecification:
        PointInTimeRecoveryEnabled: !If [IsProduction, true, false]
      SSESpecification:
        SSEEnabled: true
      StreamSpecification:
        StreamViewType: NEW_AND_OLD_IMAGES
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: EnvironmentSuffix
          Value: !Ref EnvironmentSuffix

  # Auto Scaling Role (only for production)
  ApplicationAutoScalingDynamoDBRole:
    Type: AWS::IAM::Role
    Condition: IsProduction
    Properties:
      RoleName: !Sub '${AWS::StackName}-autoscaling-role-${EnvironmentSuffix}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: application-autoscaling.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/DynamoDBAutoscalingRole

  # DynamoDB Auto Scaling (only for production)
  ReadCapacityScalableTarget:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    Condition: IsProduction
    Properties:
      MaxCapacity: 20
      MinCapacity: 5
      ResourceId: !Sub 'table/${DataTable}'
      RoleARN: !GetAtt ApplicationAutoScalingDynamoDBRole.Arn
      ScalableDimension: dynamodb:table:ReadCapacityUnits
      ServiceNamespace: dynamodb

  WriteCapacityScalableTarget:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    Condition: IsProduction
    Properties:
      MaxCapacity: 20
      MinCapacity: 5
      ResourceId: !Sub 'table/${DataTable}'
      RoleARN: !GetAtt ApplicationAutoScalingDynamoDBRole.Arn
      ScalableDimension: dynamodb:table:WriteCapacityUnits
      ServiceNamespace: dynamodb

  ReadScalingPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Condition: IsProduction
    Properties:
      PolicyName: !Sub '${AWS::StackName}-read-scaling-${EnvironmentSuffix}'
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref ReadCapacityScalableTarget
      TargetTrackingScalingPolicyConfiguration:
        TargetValue: 70.0
        ScaleInCooldown: 60
        ScaleOutCooldown: 60
        PredefinedMetricSpecification:
          PredefinedMetricType: DynamoDBReadCapacityUtilization

  WriteScalingPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Condition: IsProduction
    Properties:
      PolicyName: !Sub '${AWS::StackName}-write-scaling-${EnvironmentSuffix}'
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref WriteCapacityScalableTarget
      TargetTrackingScalingPolicyConfiguration:
        TargetValue: 70.0
        ScaleInCooldown: 60
        ScaleOutCooldown: 60
        PredefinedMetricSpecification:
          PredefinedMetricType: DynamoDBWriteCapacityUtilization

  # CloudWatch Alarms
  LambdaErrorAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${AWS::StackName}-lambda-errors-${EnvironmentSuffix}'
      AlarmDescription: 'Alarm when Lambda error rate exceeds 5%'
      ComparisonOperator: GreaterThanThreshold
      EvaluationPeriods: 2
      Threshold: 5.0
      TreatMissingData: notBreaching
      Metrics:
        - Id: e1
          Expression: '(m1/m2)*100'
          Label: 'Error Rate (%)'
        - Id: m1
          MetricStat:
            Metric:
              MetricName: Errors
              Namespace: AWS/Lambda
              Dimensions:
                - Name: FunctionName
                  Value: !Ref DataProcessorFunction
            Period: 300
            Stat: Sum
          ReturnData: false
        - Id: m2
          MetricStat:
            Metric:
              MetricName: Invocations
              Namespace: AWS/Lambda
              Dimensions:
                - Name: FunctionName
                  Value: !Ref DataProcessorFunction
            Period: 300
            Stat: Sum
          ReturnData: false

  LambdaDurationAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${AWS::StackName}-lambda-duration-${EnvironmentSuffix}'
      AlarmDescription: 'Alarm when Lambda duration exceeds 10 seconds'
      MetricName: Duration
      Namespace: AWS/Lambda
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 10000
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref DataProcessorFunction

  ApiGateway4xxAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${AWS::StackName}-api-4xx-errors-${EnvironmentSuffix}'
      AlarmDescription: 'Alarm when API Gateway 4xx errors exceed 10%'
      MetricName: 4XXError
      Namespace: AWS/ApiGateway
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 0.1
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: ApiName
          Value: !Sub '${AWS::StackName}-api-${EnvironmentSuffix}'
        - Name: Stage
          Value: !Ref EnvironmentSuffix

Outputs:
  ApiEndpoint:
    Description: 'API Gateway endpoint URL'
    Value: !Sub 'https://${DataApi}.execute-api.${AWS::Region}.amazonaws.com/${EnvironmentSuffix}/data'
    Export:
      Name: !Sub '${AWS::StackName}-ApiEndpoint-${EnvironmentSuffix}'

  HealthCheckEndpoint:
    Description: 'Health check endpoint URL'
    Value: !Sub 'https://${DataApi}.execute-api.${AWS::Region}.amazonaws.com/${EnvironmentSuffix}/health'
    Export:
      Name: !Sub '${AWS::StackName}-HealthEndpoint-${EnvironmentSuffix}'

  LambdaFunctionArn:
    Description: 'Lambda function ARN'
    Value: !GetAtt DataProcessorFunction.Arn
    Export:
      Name: !Sub '${AWS::StackName}-LambdaArn-${EnvironmentSuffix}'

  LambdaFunctionName:
    Description: 'Lambda function name'
    Value: !Ref DataProcessorFunction
    Export:
      Name: !Sub '${AWS::StackName}-LambdaName-${EnvironmentSuffix}'

  DynamoDBTableName:
    Description: 'DynamoDB table name'
    Value: !Ref DataTable
    Export:
      Name: !Sub '${AWS::StackName}-TableName-${EnvironmentSuffix}'

  DynamoDBTableArn:
    Description: 'DynamoDB table ARN'
    Value: !GetAtt DataTable.Arn
    Export:
      Name: !Sub '${AWS::StackName}-TableArn-${EnvironmentSuffix}'

  DynamoDBStreamArn:
    Description: 'DynamoDB stream ARN'
    Value: !GetAtt DataTable.StreamArn
    Export:
      Name: !Sub '${AWS::StackName}-StreamArn-${EnvironmentSuffix}'

  S3BucketName:
    Description: 'S3 bucket name'
    Value: !Ref ApplicationBucket
    Export:
      Name: !Sub '${AWS::StackName}-BucketName-${EnvironmentSuffix}'

  S3BucketArn:
    Description: 'S3 bucket ARN'
    Value: !GetAtt ApplicationBucket.Arn
    Export:
      Name: !Sub '${AWS::StackName}-BucketArn-${EnvironmentSuffix}'

  ApiGatewayId:
    Description: 'API Gateway ID'
    Value: !Ref DataApi
    Export:
      Name: !Sub '${AWS::StackName}-ApiId-${EnvironmentSuffix}'

  Environment:
    Description: 'Environment name'
    Value: !Ref Environment
    Export:
      Name: !Sub '${AWS::StackName}-Environment-${EnvironmentSuffix}'

  EnvironmentSuffix:
    Description: 'Environment suffix'
    Value: !Ref EnvironmentSuffix
    Export:
      Name: !Sub '${AWS::StackName}-EnvironmentSuffix-${EnvironmentSuffix}'
