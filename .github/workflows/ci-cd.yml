name: CI/CD Pipeline

# Special keyword [skip-jobs] can be added to commit messages to skip most jobs
# The upload-task-to-s3 job will still run when a PR is merged, regardless of this tag
# The cleanup-pr job will still run when a PR is closed, regardless of this tag
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened, closed]
  workflow_dispatch:
    inputs:
      environment_suffix:
        description: "Environment suffix for resource naming (e.g., pr123, dev, test)"
        required: false
        default: "manual"
        type: string
      skip_cleanup:
        description: "Skip cleanup/destroy step after deployment"
        required: false
        default: false
        type: boolean

permissions:
  contents: read

env:
  NODE_VERSION: "22.17.0"
  GO_VERSION: "1.23.12"
  # Use PR number for resource isolation, manual input, or fallback to 'dev' for main branch
  # Prefix with 'pr' to ensure AWS resource names start with a letter
  ENVIRONMENT_SUFFIX: ${{ github.event.inputs.environment_suffix || (github.event.number && format('pr{0}', github.event.number)) || 'dev' }}
  S3_RELEASE_BUCKET_NAME: "iac-rlhf-aws-release-342597974367-us-east-1"
  TERRAFORM_STATE_BUCKET: "iac-rlhf-tf-states-342597974367"
  TERRAFORM_STATE_BUCKET_REGION: "us-east-1"
  TERRAFORM_STATE_BUCKET_KEY: ${{ github.event.pull_request.number }}
  PULUMI_STATE_BUCKET: "iac-rlhf-pulumi-states-342597974367"
  PULUMI_BUCKET_REGION: "us-east-1"
  PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
  PULUMI_ORG: "organization"
  AWS_REGION: ${{ vars.AWS_REGION }}
  CDK_DEFAULT_REGION: ${{ vars.CDK_DEFAULT_REGION || vars.AWS_REGION || 'us-east-1' }}
  CURRENT_ACCOUNT_ID: ${{ vars.ACCOUNT_ID }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  MODEL_S3_URI: "s3://social-platform-sagemaker-342597974367-dev/model.tar.gz"
  # Go caching optimization
  GOCACHE: ${{ github.workspace }}/.cache/go-build
  GOMODCACHE: ${{ github.workspace }}/.cache/go-mod
  IAC_ANALYSIS_SUBJECT_LABEL: "Infrastructure Analysis/Monitoring"
  CICD_PIPELINE_SUBJECT_LABEL: "CI/CD Pipeline"

jobs:
  detect-metadata:
    name: Detect Project Files
    runs-on: ubuntu-24.04
    if: ${{ (github.event_name == 'pull_request' && github.event.action != 'closed' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    outputs:
      platform: ${{ steps.metadata.outputs.platform }}
      language: ${{ steps.metadata.outputs.language }}
      po_id: ${{ steps.metadata.outputs.po_id }}
      subtask: ${{ steps.metadata.outputs.subtask }}
      subject_labels: ${{ steps.metadata.outputs.subject_labels }}
      analysis_subject_label: ${{ env.IAC_ANALYSIS_SUBJECT_LABEL }}
      cicd_pipeline_subject_label: ${{ env.CICD_PIPELINE_SUBJECT_LABEL }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Fetch base branch
        run: git fetch origin main:main

      # - name: Check Project Files
      #   id: check-files
      #   run: ./scripts/check-project-files.sh

      - name: Detect metadata and validate project
        id: metadata
        run: ./scripts/detect-metadata.sh

  validate-commit-message:
    name: Validate Commit Message
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Required to fetch all history for commitlint

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "false"

      - name: Validate commit message
        run: npx commitlint --last

  build:
    name: Build
    runs-on: ubuntu-24.04
    needs: detect-metadata
    if: ${{ (github.event_name == 'pull_request' && github.event.action != 'closed' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-jobs]') && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label)}}
    environment: dev

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "false"
          upload-artifacts: "true"
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Build
        run: ./scripts/build.sh

  synth:
    name: Synth
    runs-on: ubuntu-24.04
    needs: [detect-metadata, build]
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' || github.event_name == 'workflow_dispatch' && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label) }}
    environment: dev
    permissions:
      contents: read
    outputs:
      platform: ${{ needs.detect-metadata.outputs.platform }}
      language: ${{ needs.detect-metadata.outputs.language }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        if: ${{ needs.detect-metadata.outputs.platform == 'cdk' || needs.detect-metadata.outputs.platform == 'cdktf' }}
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "true"
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Configure AWS
        if: ${{ needs.detect-metadata.outputs.platform == 'cdk' || needs.detect-metadata.outputs.platform == 'cdktf' }}
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Synth
        if: ${{ needs.detect-metadata.outputs.platform == 'cdk' || needs.detect-metadata.outputs.platform == 'cdktf' }}
        run: ./scripts/synth.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          TERRAFORM_STATE_BUCKET: ${{ env.TERRAFORM_STATE_BUCKET }}
          TERRAFORM_STATE_BUCKET_REGION: ${{ env.TERRAFORM_STATE_BUCKET_REGION }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

  infracost:
    name: Infracost (Terraform Cost Estimation)
    needs: [detect-metadata, build, synth]
    runs-on: ubuntu-24.04
    # if: >
    #   ${{
    #   github.event_name == 'pull_request' &&
    #   github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') &&
    #   needs.detect-metadata.outputs.platform == 'tf'}}
    if: false
    environment: dev
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check for Terraform files
        id: tf-check
        run: |
          if ! find lib -maxdepth 1 -name "*.tf" | grep -q .; then
            echo "No Terraform files found in lib/. Skipping Infracost job."
            echo "skip_infracost=true" >> $GITHUB_ENV
            exit 0
          fi

      - name: Setup Terraform
        if: env.skip_infracost != 'true'
        uses: hashicorp/setup-terraform@v3

      - name: Setup Infracost
        if: env.skip_infracost != 'true'
        uses: infracost/actions/setup@v3
        with:
          api-key: ${{ secrets.INFRACOST_API_KEY }}

      - name: Setup Environment (variables)
        if: env.skip_infracost != 'true'
        run: |
          echo "TERRAFORM_STATE_BUCKET=${{ env.TERRAFORM_STATE_BUCKET }}" >> $GITHUB_ENV
          echo "TERRAFORM_STATE_BUCKET_REGION=${{ env.TERRAFORM_STATE_BUCKET_REGION }}" >> $GITHUB_ENV
          echo "ENVIRONMENT_SUFFIX=${{ env.ENVIRONMENT_SUFFIX }}" >> $GITHUB_ENV

      - name: Terraform Init
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: terraform init

      - name: Terraform Plan
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: terraform plan -out=tfplan
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Convert plan to JSON
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: terraform show -json tfplan > plan.json
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Run Infracost breakdown
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: infracost breakdown --path=plan.json --format=json --out-file=../infracost.json
        env:
          INFRACOST_API_KEY: ${{ secrets.INFRACOST_API_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Post Infracost comment
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: |
          infracost comment github --path=../infracost.json \
                                 --pull-request=${{ github.event.pull_request.number }} \
                                 --repo=${{ github.repository }} \
                                 --github-token=${{ secrets.GITHUB_TOKEN }} \
                                 --behavior=update
        env:
          INFRACOST_API_KEY: ${{ secrets.INFRACOST_API_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}
  analysis:
    name: Analysis
    runs-on: ubuntu-24.04
    needs: detect-metadata
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') && contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) }}
    environment: dev
    env:
      AWS_ENDPOINT_URL: http://127.0.0.1:5001
      AWS_ACCESS_KEY_ID: test
      AWS_SECRET_ACCESS_KEY: test
      AWS_DEFAULT_REGION: us-east-1
    permissions:
      contents: write
      pull-requests: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          ref: ${{ github.head_ref }}

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "false"
          is-analysis: "true"

      - name: Run analysis
        run: ./scripts/analysis.sh
        env:
          IAC_ANALYSIS_SUBJECT_LABEL: ${{ needs.detect-metadata.outputs.analysis_subject_label }}
          GITHUB_HEAD_REF: ${{ github.head_ref }}

      - name: Upload analysis results as artifact
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: lib/analysis-results.txt
          if-no-files-found: warn

  cicd-pipeline-optimization:
    name: CICD Pipeline Optimization
    runs-on: ubuntu-24.04
    needs: detect-metadata
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') && contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label) }}
    environment: dev
    permissions:
      contents: write
      pull-requests: write
      actions: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          ref: ${{ github.head_ref }}

      - name: Execute CI/CD Pipeline Script
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_HEAD_REF: ${{ github.head_ref }}
        run: ./scripts/cicd-pipeline.sh

      - name: Upload Pipeline Configuration
        uses: actions/upload-artifact@v4
        with:
          name: cicd-pipeline-config
          path: lib/ci-cd.yml
          if-no-files-found: error

  deploy:
    name: Deploy
    runs-on: ubuntu-24.04
    needs: [detect-metadata, synth]
    if: ${{ (github.event_name == 'pull_request' && github.event.action != 'closed' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-jobs]') && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label)}}
    environment: dev

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "true"
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      # Terraform State Management Setup
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3

      # (Removed DynamoDB lock table step per PR review)

      - name: Bootstrap
        run: ./scripts/bootstrap.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          REPOSITORY: ${{ github.repository }}
          COMMIT_AUTHOR: ${{ github.event.head_commit.author.name || github.actor }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

      - name: Deploy
        run: ./scripts/deploy.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          REPOSITORY: ${{ github.repository }}
          COMMIT_AUTHOR: ${{ github.event.head_commit.author.name || github.actor }}
          TERRAFORM_STATE_BUCKET: ${{ env.TERRAFORM_STATE_BUCKET }}
          TERRAFORM_STATE_BUCKET_REGION: ${{ env.TERRAFORM_STATE_BUCKET_REGION }}
          TERRAFORM_STATE_BUCKET_KEY: ${{ env.ENVIRONMENT_SUFFIX }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}
          CURRENT_ACCOUNT_ID: ${{ env.CURRENT_ACCOUNT_ID }}

      # Note: Deployment outputs are now collected by the deploy.sh script

      - name: Upload Deployment Outputs
        uses: actions/upload-artifact@v4
        with:
          name: cfn-outputs
          path: |
            cfn-outputs/
            cdk-stacks.json
  lint:
    name: Lint
    runs-on: ubuntu-24.04
    needs: [detect-metadata, build]
    if: ${{ (github.event_name == 'pull_request' && github.event.action != 'closed' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-jobs]') && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label)}}
    environment: qa
    outputs:
      platform: ${{ needs.detect-metadata.outputs.platform }}
      language: ${{ needs.detect-metadata.outputs.language }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "true"
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      # Python setup is handled by the setup-environment action

      - name: Run Linting
        run: ./scripts/lint.sh

  unit-tests:
    name: Unit Testing
    runs-on: ubuntu-24.04
    needs: [detect-metadata, lint]
    if: ${{ (github.event_name == 'pull_request' && github.event.action != 'closed' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-jobs]') && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label) }}
    environment: qa

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "true"
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Run unit tests
        run: ./scripts/unit-tests.sh

      - name: Prepare coverage reports for Java projects
        if: ${{ needs.detect-metadata.outputs.language == 'java' }}
        run: |
          echo "Preparing Java coverage reports for upload..."
          echo "Debug: Checking current directory structure:"
          ls -la

          echo "Debug: Checking build directory:"
          if [ -d "build" ]; then
            ls -la build/
            if [ -d "build/reports" ]; then
              echo "Reports directory contents:"
              ls -la build/reports/
              if [ -d "build/reports/jacoco" ]; then
                echo "JaCoCo directory contents:"
                find build/reports/jacoco -type f | head -10
              fi
            fi
          else
            echo "No build directory found"
          fi

          mkdir -p coverage

          # Try different possible locations for JaCoCo reports
          if [ -d "build/reports/jacoco/test/" ]; then
            cp -r build/reports/jacoco/test/* coverage/
            echo "âœ… Copied JaCoCo reports from build/reports/jacoco/test/ to coverage/ directory"
          elif [ -d "build/reports/jacoco/" ]; then
            cp -r build/reports/jacoco/* coverage/
            echo "âœ… Copied JaCoCo reports from build/reports/jacoco/ to coverage/ directory"
          else
            echo "âš ï¸ JaCoCo reports not found in expected locations"
            # Create a placeholder to avoid upload failure
            echo "No coverage reports generated" > coverage/no-reports.txt
          fi

          echo "Final coverage directory contents:"
          ls -la coverage/
      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            coverage/
            cov.json

  claude-task-analyze:
    runs-on: ubuntu-24.04
    name: "Claude Task Analysis"
    needs: [detect-metadata, unit-tests]
    if: ${{ (github.event_name == 'pull_request' && github.event.action != 'closed' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-jobs]') && needs.detect-metadata.outputs.subtask != 'IaC Program Optimization'}}
    permissions:
      contents: write
      pull-requests: write
      issues: write
      id-token: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event_name == 'pull_request' && format('refs/pull/{0}/head', github.event.pull_request.number) || github.ref }}

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "false"

      - name: Run Claude Task Analysis
        uses: anthropics/claude-code-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          allowed_tools: "Bash,Read,Write,Edit,MultiEdit,Glob,Grep,LS,Task,TodoWrite"
          trigger_phrase: ""
          custom_instructions: |
            Analyze the IAC task files in the lib/ folder and generate a report showing which resources have deletion protection enabled.
            This helps identify resources that will REMAIN after stack deletion.

            Your task:
            1. Read all IAC code files in the lib/ folder (including TypeScript, Python, Java, Go, Terraform, CloudFormation, etc.)
            2. Identify all AWS resources defined in the infrastructure code
            3. For each resource, check ONLY for deletion protection settings:
               - Look for properties like: DeletionProtection, deletion_protection, DeletionPolicy: Retain, etc.
               - Common patterns:
                 * CloudFormation: DeletionProtection: true, DeletionPolicy: Retain
                 * Terraform: deletion_protection = true, prevent_destroy = true
                 * CDK: deletionProtection: true, removalPolicy: RemovalPolicy.RETAIN
                 * RDS: DeletionProtection: true
                 * DynamoDB: DeletionProtectionEnabled: true
                 * S3: (bucket-level policy prevents deletion)
               - Note: RDS databases should NOT have delete protection enabled (deleteProtection should be false for RDS)
            4. For each resource, determine:
               - Resource name/identifier
               - deleteProtection: true if deletion protection is enabled, false otherwise
               - cost: Estimate the monthly cost (for resources that will remain after deletion)

            5. Generate a markdown table with the following columns:
               - resource: The resource name/identifier
               - deleteProtection: true/false based on deletion protection settings
               - cost: Estimated monthly cost (in USD, or "N/A" if not applicable)

            6. At the bottom of the table, add a summary row with:
               - Total monthly cost (sum of all costs, excluding "N/A")
               - Total per day cost (monthly cost / 30)

            7. Post the report as a GitHub comment on the pull request.

            Example table format:
            | resource | deleteProtection | cost |
            |----------|------------------|------|
            | s3-bucket-myapp | true | $0.023 |
            | rds-database-prod | false | $150.00 |
            | dynamodb-table-users | true | $25.00 |
            | **Total (per month)** | | **$175.023** |
            | **Total (per day)** | | **$5.83** |

            Important:
            - ONLY check for deletion protection settings - ignore encryption, MFA, backup, versioning, etc.
            - Focus on identifying resources that will remain after stack deletion
            - Resources with deleteProtection: true will persist after stack deletion
            - For cost estimation, use standard AWS pricing or reasonable estimates
            - If cost cannot be determined, use "N/A" and exclude from totals
            - Calculate per day cost as monthly cost divided by 30
            - Post the complete report as a GitHub comment with the cost summary at the bottom

  # mocked-integration-tests:
  #   name: Mocked Integration Tests
  #   runs-on: ubuntu-24.04
  #   needs: unit-tests

  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v4

  #     - name: Setup Environment
  #       uses: ./.github/actions/setup-environment
  #       with:
  #         node-version: ${{ env.NODE_VERSION }}
  #         download-artifacts: "true"

  #     - name: Run mocked integration tests
  #       run: npm run test:integration
  #       env:
  #         # Mock environment variables for testing
  #         API_GATEWAY_ENDPOINT: "https://mock-api.example.com/prod"
  #         READ_ONLY_API_KEY: "mock-readonly-key"
  #         ADMIN_API_KEY: "mock-admin-key"

  integration-tests-live:
    name: Integration Tests (Live)
    runs-on: ubuntu-24.04
    needs: [detect-metadata, lint, unit-tests, deploy]
    environment: qa
    if: ${{ (github.event_name == 'pull_request' && github.event.action != 'closed' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-jobs]') && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label)}}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "true"
          platform: ${{ needs.detect-metadata.outputs.platform }}

      - name: Download Deployment Outputs
        uses: actions/download-artifact@v4
        with:
          name: cfn-outputs
          path: .

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Run integration tests against live environment
        run: ./scripts/integration-tests.sh
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          CI: "1" # Set CI for the entire step
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

  claude-code-action:
    runs-on: ubuntu-24.04
    name: "Claude Review"
    needs: [integration-tests-live, analysis, cicd-pipeline-optimization]
    if: always() && !cancelled() && (needs.analysis.result == 'success' || needs.analysis.result == 'skipped') && (needs.cicd-pipeline-optimization.result == 'success' || needs.cicd-pipeline-optimization.result == 'skipped') && (needs.integration-tests-live.result == 'success' || needs.integration-tests-live.result == 'skipped')
    permissions:
      contents: write
      pull-requests: write
      issues: write
      id-token: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: refs/pull/${{ github.event.pull_request.number }}/head

      - name: Check for required documentation files
        id: docs-check
        run: |
          if [ ! -f "lib/PROMPT.md" ]; then
            echo "âŒ lib/PROMPT.md not found, exiting with failure"
            exit 1
          fi

          if [ ! -f "lib/MODEL_RESPONSE.md" ]; then
            echo "âŒ lib/MODEL_RESPONSE.md not found, exiting with failure"
            exit 1
          fi

          if [ ! -f "lib/IDEAL_RESPONSE.md" ]; then
            echo "âŒ lib/IDEAL_RESPONSE.md not found, exiting with failure"
            exit 1
          fi

          if [ ! -f "lib/MODEL_FAILURES.md" ]; then
            echo "âŒ lib/MODEL_FAILURES.md not found, exiting with failure"
            exit 1
          fi

      - name: Verify IaC Program Optimization script exists
        if: ${{ contains(needs.detect-metadata.outputs.subject_labels, 'Infrastructure Analysis/Monitoring') }}
        run: |
          if [ ! -f "lib/analyse.py" ] && [ ! -f "lib/analyse.sh" ]; then
            echo "âŒ Expected lib/analyse.py or lib/analyse.sh for IaC Program Optimization task"
            exit 1
          fi

      - name: Run Claude PR Review Action
        uses: anthropics/claude-code-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          allowed_tools: "Bash,Read,Write,Edit,MultiEdit,Glob,Grep,LS,Task,TodoWrite"
          trigger_phrase: ""
          custom_instructions: |
            CRITICAL: you MUST validate the latest PROMPT file format, and add a github comment if it appears to be AI-generated rather than human-written:
            1. Identify all the PROMPT file (PROMPT.md, PROMPT2.md, PROMPT3.md, etc.) - always use the highest numbered one
            2. Read the PROMPT files
            3. Assess whether the content looks human-generated or AI-generated
            4. Look for signs of AI generation such as:
                - Emojis or special symbols (icons) used for formatting
                - Table structures
                - Overly formal or template-like language
                - Logs are allowed when we have multiple prompt files. 
                - Perfect formatting that suggests AI assistance
                - LLM Flavoured text, such as: "Here is a **comprehensive and high-level prompt** for your use..."
            5. If  any PROMPT file appears to be AI-generated rather than human-written, fail the job by exiting with code 1.
            6. Also validate that for each PROMPT file, there is a corresponding MODEL_RESPONSE file (e.g., PROMPT.md -> MODEL_RESPONSE.md, PROMPT2.md -> MODEL_RESPONSE2.md, etc.) and that it is well-formatted.
            7. PROMPT2.md and PROMPT3.md are optional, but if they exist, they must also be validated and it can contain Deployment/Test/Error logs as well.

            CRITICAL: you MUST validate lib/IDEAL_RESPONSE.md, read .claude/agents/iac-infra-qa-trainer.md to understand how that file should have been created.
            1. Read lib/IDEAL_RESPONSE.md if it exists
            2. lib/IDEAL_RESPONSE.md should be well-formatted, markdown.
            3. Important: There should not be code outside proper code blocks (```python, ```bash, etc.)
            4. Every code file inside lib/ folder should be represented in lib/IDEAL_RESPONSE.md in code_blocks.
            5. There should not be references in the lib/IDEAL_RESPONSE.md to the QA process, unit tests or integration tests.
            6. If the lib/IDEAL_RESPONSE.md does not meet the above criteria, fail the job by exiting with code 1.

            CRITICAL WARNING - FILE CONTEXT:
            - lib/MODEL_RESPONSE.md = Initial model output (MAY contain errors like Maven, multi-stack, etc.)
            - lib/IDEAL_RESPONSE.md = Final corrected code (THIS is what you validate for platform/language compliance)
            - lib/MODEL_FAILURES.md = Documentation of what WAS FIXED (past tense) - NOT current errors!

            When validating platform/language compliance, you MUST:
            1. Run: bash ./.claude/scripts/validate-code-platform.sh
            2. This script checks lib/IDEAL_RESPONSE.md (NOT MODEL_RESPONSE.md) against metadata.json
            3. If MODEL_FAILURES.md mentions "Maven â†’ Gradle" or "multi-stack â†’ single stack", those are PAST fixes
            4. DO NOT report those as current problems in IDEAL_RESPONSE.md
            5. Only validate what is CURRENTLY in lib/IDEAL_RESPONSE.md

            Follow instructions in .claude/agents/iac-code-reviewer.md. Do not commit any changes, but allow the metadata.json file to be updated.
            Important: The Metadata Enhancement phase in .claude/agents/iac-code-reviewer.md is very important for this project. Make sure that the
            metadata.json file is updated with the fields stated there. If the metadata.json file after the review does not contain the fields:
            - training_quality
            - aws_services
            then add a github comment indicating the issue

            This validation is mandatory and must be completed before any other review activities.

            Now follow the instructions in .claude/agents/iac-code-reviewer.md 
            SCORE:<numeric_value>
            Example: SCORE:8

            - This must always appear on its own line at the very end of your output.
            - Do not include extra text, markdown, or emojis on that line.
            - The numeric value (0â€“10) represents the final quality score.
            - Continue to post your detailed GitHub comment as usual.

            Once your review is complete, post the summary comment and finish execution successfully.
            Do not exit with a non-zero code unless explicitly instructed by the workflow.

      - name: Extract Claude Quality Score from PR Comment
        id: extract
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ” Fetching latest Claude review comment..."
          gh pr view ${{ github.event.pull_request.number }} --comments --json comments \
            | jq -r '.comments[].body' > all_comments.txt

          echo "ðŸ€ Searching for quality score pattern..."
          # Match any of these:
          # - "**Final Score: 9.5/10**"
          # - "Training Quality: 9/10"
          # - "SCORE:10"
          # Handles decimals, optional markdown, emojis, and spaces
          SCORE=$(grep -Eo '(\*\*)?(Final|Training)[[:space:]]*Quality:?[[:space:]]*[0-9]+(\.[0-9]+)?/10(\*\*)?|SCORE:[[:space:]]*[0-9]+(\.[0-9]+)?' all_comments.txt \
            | tail -1 | grep -Eo '[0-9]+(\.[0-9]+)?' | head -1)

          if [ -z "$SCORE" ]; then
            echo "âš ï¸ Could not find any quality score in PR comments. Defaulting to 0."
            SCORE=0
          fi

          echo "Claude quality score: $SCORE"
          echo "quality_score=$SCORE" >> $GITHUB_OUTPUT

      - name: Enforce Quality Threshold
        id: quality_gate
        run: |
          SCORE=${{ steps.extract.outputs.quality_score }}
          echo "Evaluating Claude quality gate..."
          if (( SCORE < 8 )); then
            echo "âŒ Quality score ($SCORE) below threshold (8)."
            exit 1
          else
            echo "âœ… Quality score ($SCORE) meets or exceeds threshold (8)."
          fi

      - name: Upload updated metadata.json
        uses: actions/upload-artifact@v4
        with:
          name: updated-metadata
          path: metadata.json
          if-no-files-found: warn
    outputs:
      quality_score: ${{ steps.extract.outputs.quality_score }}
  cleanup:
    name: Cleanup (Destroy Resources)
    runs-on: ubuntu-24.04
    needs: [detect-metadata, integration-tests-live, claude-code-action, cicd-pipeline-optimization]
    if: ${{ always() && !cancelled() && (needs.integration-tests-live.result == 'success' || needs.integration-tests-live.result == 'skipped') && needs.claude-code-action.result == 'success' && ((github.event_name == 'pull_request' && github.event.action != 'closed') || (github.event_name == 'workflow_dispatch' && !inputs.skip_cleanup)) && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    environment: stage

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "false"
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Destroy Resources (cleanup any leftover resources)
        if: ${{ !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label) }}
        run: ./scripts/destroy.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          TERRAFORM_STATE_BUCKET: ${{ env.TERRAFORM_STATE_BUCKET }}
          TERRAFORM_STATE_BUCKET_REGION: ${{ env.TERRAFORM_STATE_BUCKET_REGION }}
          TERRAFORM_STATE_BUCKET_KEY: ${{ env.ENVIRONMENT_SUFFIX }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

      - name: Skip Cleanup (Analysis or CI/CD Pipeline task)
        if: ${{ contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) || contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label) }}
        run: |
          echo "â„¹ï¸ Skipping resource cleanup for Analysis or CI/CD Pipeline task"
          echo "No infrastructure resources were deployed that need cleanup"
  debug-claude-outputs:
    name: Debug Claude outputs
    runs-on: ubuntu-24.04
    needs: [claude-code-action]
    if: always()
    steps:
      - name: Dump needs info
        run: |
          echo "needs.claude-code-action.result=${{ needs.claude-code-action.result }}"
          echo "needs.claude-code-action.outputs.quality_score='${{ needs.claude-code-action.outputs.quality_score }}'"
          echo "---- full needs json ----"
          echo '${{ toJson(needs) }}'

  archive-folders:
    name: Archive Folders and Reset Repository
    runs-on: ubuntu-24.04
    needs: [detect-metadata, cleanup]
    environment: stage
    if: ${{ always() && !cancelled() && needs.cleanup.result == 'success' && needs.detect-metadata.result == 'success' && ((github.event_name == 'pull_request' && github.event.action != 'closed') || (github.event_name == 'workflow_dispatch')) && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          repository: ${{ github.repository }}
          ref: ${{ github.head_ref }}

      - name: Download coverage reports
        if: ${{ !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) && !contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label) }}
        uses: actions/download-artifact@v4
        with:
          name: coverage-reports
          path: coverage/

      - name: Download updated metadata
        uses: actions/download-artifact@v4
        with:
          name: updated-metadata
          path: .

      - name: Download analysis results
        if: ${{ contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.analysis_subject_label) }}
        uses: actions/download-artifact@v4
        with:
          name: analysis-results
          path: lib/

      - name: Download CI/CD Pipeline configuration
        if: ${{ contains(needs.detect-metadata.outputs.subject_labels, needs.detect-metadata.outputs.cicd_pipeline_subject_label) }}
        uses: actions/download-artifact@v4
        with:
          name: cicd-pipeline-config
          path: lib/

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Archive folders and reset repository
        run: |
          # Configure Git
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"

          # Use metadata from detect-metadata job
          PLATFORM="${{ needs.detect-metadata.outputs.platform }}"
          LANGUAGE="${{ needs.detect-metadata.outputs.language }}"
          echo "Using platform: $PLATFORM, language: $LANGUAGE"

          # Update metadata.json with coverage information and commit author
          # Get commit author from GitHub context
          COMMIT_AUTHOR="${{ github.event.pull_request.user.login || github.actor }}"
          echo "Commit author: $COMMIT_AUTHOR"

          # Extract coverage percentages based on language
          if [ "$LANGUAGE" = "yml" ]; then
            echo "CI/CD Pipeline task - no unit test coverage required"
            LINES_COVERAGE=100
            BRANCHES_COVERAGE=100
          elif [ "$LANGUAGE" = "py" ]; then
            echo "Extracting Python coverage from cov.json..."
            if [ -f "cov.json" ]; then
              LINES_COVERAGE=$(jq -r '.totals.percent_covered' cov.json)
              # Calculate branch coverage percentage
              BRANCHES_NUM=$(jq -r '.totals.num_branches' cov.json)
              if [ "$BRANCHES_NUM" = "0" ] || [ "$BRANCHES_NUM" = "null" ]; then
                # No branches to cover, set to 100%
                BRANCHES_COVERAGE=100
              else
                COVERED_BRANCHES=$(jq -r '.totals.covered_branches' cov.json)
                # Calculate percentage: (covered_branches / num_branches) * 100
                BRANCHES_COVERAGE=$(awk "BEGIN {print ($COVERED_BRANCHES / $BRANCHES_NUM) * 100}")
              fi
            else
              echo "Warning: cov.json not found, setting default coverage values"
              LINES_COVERAGE=100
              BRANCHES_COVERAGE=100
            fi
          elif [ "$LANGUAGE" = "go" ]; then
            echo "Extracting Go coverage from coverage-summary.json..."
            if [ -f "coverage/coverage-summary.json" ]; then
              LINES_COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json)
              BRANCHES_COVERAGE=$(jq -r '.total.branches.pct' coverage/coverage-summary.json)
            else
              echo "Warning: Go coverage-summary.json not found, setting default coverage values"
              LINES_COVERAGE=100
              BRANCHES_COVERAGE=100
            fi
          else
            echo "Extracting TypeScript/JavaScript coverage from coverage-summary.json..."
            if [ -f "coverage/coverage-summary.json" ]; then
              LINES_COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json)
              BRANCHES_COVERAGE=$(jq -r '.total.branches.pct' coverage/coverage-summary.json)
            else
              echo "Warning: coverage-summary.json not found, setting default coverage values"
              LINES_COVERAGE=100
              BRANCHES_COVERAGE=100
            fi
          fi

          # If coverage is "Unknown", set to 100
          if [ "$LINES_COVERAGE" = "Unknown" ]; then
            LINES_COVERAGE=100
          fi
          if [ "$BRANCHES_COVERAGE" = "Unknown" ]; then
            BRANCHES_COVERAGE=100
          fi

          echo "Lines coverage: $LINES_COVERAGE%"
          echo "Branches coverage: $BRANCHES_COVERAGE%"

          # Update metadata.json with coverage information and commit author (assuming it always exists)
          jq --arg lines "$LINES_COVERAGE" --arg branches "$BRANCHES_COVERAGE" --arg author "$COMMIT_AUTHOR" '. + {coverage: {lines: ($lines|tonumber), branches: ($branches|tonumber)}, author: $author}' metadata.json > metadata.json.tmp
          mv metadata.json.tmp metadata.json
          echo "Updated metadata.json with coverage information and commit author"

          cat metadata.json

          echo "Current directory contents before archiving:"
          ls -la

          # Get Docker S3 location from the previous step and add it to metadata.json
          DOCKER_S3_LOCATION="${DOCKER_S3_LOCATION}"
          echo "Docker S3 location from previous step: $DOCKER_S3_LOCATION"

          # Add the dockerS3Location to metadata.json
          jq --arg location "$DOCKER_S3_LOCATION" '. + {dockerS3Location: $location}' metadata.json > metadata.json.tmp
          mv metadata.json.tmp metadata.json
          echo "Updated metadata.json with dockerS3Location: $DOCKER_S3_LOCATION"

          # Create archive directory with platform, language, and PR number
          ARCHIVE_DIR="archive/${PLATFORM}-${LANGUAGE}/Pr${{ github.event.number }}"
          mkdir -p "$ARCHIVE_DIR"
          echo "Created archive directory: $ARCHIVE_DIR"

            # Define list of paths to move to archive
            PATHS_TO_ARCHIVE=(
            "lib"
            "bin" 
            "test"
            "tests"
            "cdk.json"
            "metadata.json"
            "tap.py"
            "tap.go"
            "setup.js"
            "cdktf.json"
            "Pulumi.yaml"
            )

          # Move paths to archive
          for path in "${PATHS_TO_ARCHIVE[@]}"; do
          if [[ -d "$path" || -f "$path" ]]; then
            mv "$path" "$ARCHIVE_DIR"/
            echo "Moved $path to archive"
          else
            echo "Path $path not found, skipping"
          fi
          done

          # Check if there are changes to commit
          if git diff --quiet && git diff --cached --quiet; then
            echo "No changes to commit - no folders found to archive"
          else
            # Extract metadata for commit message
            METADATA_FILE="$ARCHIVE_DIR/metadata.json"
            METADATA_PLATFORM=$(jq -r '.platform' "$METADATA_FILE")
            METADATA_PO_ID=$(jq -r '.po_id' "$METADATA_FILE")
            METADATA_SUBTASK=$(jq -r '.subtask | ascii_downcase' "$METADATA_FILE")
            METADATA_SUBJECT_LABELS=$(jq -r '.subject_labels | join(", ")' "$METADATA_FILE")

            METADATA_AUTHOR=$(jq -r '.author' "$METADATA_FILE")

            # Truncate subject_labels to 100 characters if needed
            if [ ${#METADATA_SUBJECT_LABELS} -gt 100 ]; then
              METADATA_SUBJECT_LABELS="${METADATA_SUBJECT_LABELS:0:97}..." # 97 chars + "..." = 100
            fi

            COMMIT_SUBJECT="feat(${METADATA_PLATFORM}): ${METADATA_PO_ID} ${METADATA_SUBTASK}"
            COMMIT_BODY="${METADATA_SUBJECT_LABELS}\nAuthor: ${METADATA_AUTHOR}"

            git add -A
            git commit -m "${COMMIT_SUBJECT}" -m "${COMMIT_BODY}" -m "[skip-jobs]"
            git push origin HEAD
            echo "Archive committed to current branch"
          fi

  upload-task-to-s3:
    name: Upload Task to S3
    runs-on: ubuntu-24.04
    environment: release
    if: ${{ github.event_name == 'pull_request' && github.event.pull_request.merged == true }}
    permissions:
      contents: read

    steps:
      - name: Checkout merged code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          repository: ${{ github.repository }}
          ref: ${{ github.event.pull_request.merge_commit_sha }}

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Extract platform and language for S3 upload
        id: extract-metadata
        run: |
          # We need to find the specific archive folder for this PR
          # Since we don't know platform/language yet, we'll search for the PR-specific folder
          PR_FOLDER_PATTERN="archive/*/Pr${{ github.event.number }}"

          # Find the archive folder for this specific PR
          ARCHIVE_FOLDER=""
          for folder in $PR_FOLDER_PATTERN; do
            if [ -d "$folder" ]; then
              ARCHIVE_FOLDER="$folder"
              break
            fi
          done

          if [ -n "$ARCHIVE_FOLDER" ] && [ -f "$ARCHIVE_FOLDER/metadata.json" ]; then
            echo "Found archive folder: $ARCHIVE_FOLDER"
            echo "Found metadata.json at: $ARCHIVE_FOLDER/metadata.json"
            PLATFORM=$(jq -r '.platform // "unknown"' "$ARCHIVE_FOLDER/metadata.json")
            LANGUAGE=$(jq -r '.language // "unknown"' "$ARCHIVE_FOLDER/metadata.json")
          else
            echo "Warning: Could not find archive folder or metadata.json for PR ${{ github.event.number }}"
            echo "Available archive folders:"
            ls -la archive/ || echo "No archive directory found"
            PLATFORM="unknown"
            LANGUAGE="unknown"
          fi
          echo "platform=$PLATFORM" >> $GITHUB_OUTPUT
          echo "language=$LANGUAGE" >> $GITHUB_OUTPUT
          echo "Extracted platform: $PLATFORM, language: $LANGUAGE"

      - name: Upload archive folder to S3
        run: |
          PLATFORM="${{ steps.extract-metadata.outputs.platform }}"
          LANGUAGE="${{ steps.extract-metadata.outputs.language }}"
          S3_PREFIX="${PLATFORM}-${LANGUAGE}/Pr${{ github.event.number }}"

          echo "Uploading archive folder to S3 bucket: ${{ env.S3_RELEASE_BUCKET_NAME }}"
          echo "S3 prefix: $S3_PREFIX"

          # Check if archive folder exists
          if [ -d "archive/${S3_PREFIX}" ]; then
            # Upload the archive folder contents to S3, preserving folder structure
            aws s3 sync "archive/${S3_PREFIX}/" "s3://${{ env.S3_RELEASE_BUCKET_NAME }}/${S3_PREFIX}/" \
              --delete \
              --exclude "*.git*" \
              --exclude "node_modules/*"
            echo "Successfully uploaded archive to S3"
          else
            echo "Archive folder archive/${S3_PREFIX} not found, nothing to upload"
            exit 1
          fi
      - name: Verify S3 upload
        run: |
          PLATFORM="${{ steps.extract-metadata.outputs.platform }}"
          LANGUAGE="${{ steps.extract-metadata.outputs.language }}"
          S3_PREFIX="${PLATFORM}-${LANGUAGE}/Pr${{ github.event.number }}"

          echo "Verifying S3 upload for prefix: $S3_PREFIX"
          aws s3 ls "s3://${{ env.S3_RELEASE_BUCKET_NAME }}/${S3_PREFIX}/" --recursive || echo "No files found or access denied"

  cleanup-pr:
    name: Cleanup (PR Closed)
    runs-on: ubuntu-24.04
    # This job should run regardless of the [skip-jobs] tag since it's for cleanup
    if: github.event_name == 'pull_request' && github.event.action == 'closed' && !github.event.pull_request.merged
    environment: release

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "false"

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Destroy Resources (if resources exist)
        run: ./scripts/destroy.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          TERRAFORM_STATE_BUCKET: ${{ env.TERRAFORM_STATE_BUCKET }}
          TERRAFORM_STATE_BUCKET_REGION: ${{ env.TERRAFORM_STATE_BUCKET_REGION }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

  semantic-release:
    name: Semantic Release
    runs-on: ubuntu-24.04
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    # permissions:
    #   contents: write
    #   issues: write
    #   pull-requests: write
    concurrency:
      group: semantic_release_pipeline
      cancel-in-progress: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: "false"

      - name: Run semantic-release
        run: npm run release
        env:
          GITHUB_TOKEN: ${{ secrets.SEMANTIC_RELEASE_PAT }}
