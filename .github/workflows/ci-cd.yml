name: CI/CD Pipeline

# Special keyword [skip-jobs] can be added to commit messages to skip most jobs
# The upload-task-to-s3 job will still run when a PR is merged, regardless of this tag
# The cleanup-pr job will still run when a PR is closed, regardless of this tag

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened, closed]
  workflow_dispatch:

permissions:
  contents: read

env:
  NODE_VERSION: '22.17.0'
  GO_VERSION: '1.23.12'
  # Use PR number for resource isolation, fallback to 'dev' for main branch
  # Prefix with 'pr' to ensure AWS resource names start with a letter
  ENVIRONMENT_SUFFIX: ${{ github.event.number && format('pr{0}', github.event.number) || 'dev' }}
  S3_RELEASE_BUCKET_NAME: 'iac-rlhf-aws-release-342597974367-us-east-1'
  TERRAFORM_STATE_BUCKET: 'iac-rlhf-tf-states-342597974367'
  TERRAFORM_STATE_BUCKET_REGION: 'us-east-1'
  TERRAFORM_STATE_BUCKET_KEY: ${{ github.event.pull_request.number }}
  PULUMI_STATE_BUCKET: 'iac-rlhf-pulumi-states-342597974367'
  PULUMI_BUCKET_REGION: 'us-east-1'
  PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
  PULUMI_ORG: 'organization'
  AWS_REGION: ${{ vars.AWS_REGION }}
  CURRENT_ACCOUNT_ID: '342597974367'
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  # Go caching optimization
  GOCACHE: ${{ github.workspace }}/.cache/go-build
  GOMODCACHE: ${{ github.workspace }}/.cache/go-mod

jobs:
  detect-metadata:
    name: Detect Project Files
    runs-on: ubuntu-24.04
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    outputs:
      platform: ${{ steps.metadata.outputs.platform }}
      language: ${{ steps.metadata.outputs.language }}
      po_id: ${{ steps.metadata.outputs.po_id }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Detect metadata and validate project
        id: metadata
        run: ./scripts/detect-metadata.sh

  build:
    name: Build
    runs-on: ubuntu-24.04
    needs: detect-metadata
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    environment: dev

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: 'false'
          upload-artifacts: 'true'
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Build
        run: ./scripts/build.sh

  synth:
    name: Synth
    runs-on: ubuntu-24.04
    needs: [detect-metadata, build]
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' }}
    environment: dev
    permissions:
      contents: read
    outputs:
      platform: ${{ needs.detect-metadata.outputs.platform }}
      language: ${{ needs.detect-metadata.outputs.language }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        if: ${{ needs.detect-metadata.outputs.platform == 'cdk' || needs.detect-metadata.outputs.platform == 'cdktf' }}
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: 'true'
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Configure AWS
        if: ${{ needs.detect-metadata.outputs.platform == 'cdk' || needs.detect-metadata.outputs.platform == 'cdktf' }}
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Synth
        if: ${{ needs.detect-metadata.outputs.platform == 'cdk' || needs.detect-metadata.outputs.platform == 'cdktf' }}
        run: ./scripts/synth.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          TERRAFORM_STATE_BUCKET: ${{ env.TERRAFORM_STATE_BUCKET }}
          TERRAFORM_STATE_BUCKET_REGION: ${{ env.TERRAFORM_STATE_BUCKET_REGION }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

  infracost:
    name: Infracost (Terraform Cost Estimation)
    needs: [detect-metadata, build, synth]
    runs-on: ubuntu-24.04
    # if: >
    #   ${{
    #   github.event_name == 'pull_request' &&
    #   github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') &&
    #   needs.detect-metadata.outputs.platform == 'tf'}}
    if: false
    environment: dev
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check for Terraform files
        id: tf-check
        run: |
          if ! find lib -maxdepth 1 -name "*.tf" | grep -q .; then
            echo "No Terraform files found in lib/. Skipping Infracost job."
            echo "skip_infracost=true" >> $GITHUB_ENV
            exit 0
          fi

      - name: Setup Terraform
        if: env.skip_infracost != 'true'
        uses: hashicorp/setup-terraform@v3

      - name: Setup Infracost
        if: env.skip_infracost != 'true'
        uses: infracost/actions/setup@v3

      - name: Setup Environment (variables)
        if: env.skip_infracost != 'true'
        run: |
          echo "TERRAFORM_STATE_BUCKET=${{ env.TERRAFORM_STATE_BUCKET }}" >> $GITHUB_ENV
          echo "TERRAFORM_STATE_BUCKET_REGION=${{ env.TERRAFORM_STATE_BUCKET_REGION }}" >> $GITHUB_ENV
          echo "ENVIRONMENT_SUFFIX=${{ env.ENVIRONMENT_SUFFIX }}" >> $GITHUB_ENV

      - name: Terraform Init
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: terraform init

      - name: Terraform Plan
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: terraform plan -out=tfplan
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Convert plan to JSON
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: terraform show -json tfplan > plan.json
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Run Infracost breakdown
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: infracost breakdown --path=plan.json --format=json --out-file=../infracost.json
        env:
          INFRACOST_API_KEY: ${{ secrets.INFRACOST_API_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Post Infracost comment
        if: env.skip_infracost != 'true'
        working-directory: lib
        run: |
          infracost comment github --path=../infracost.json \
                                 --pull-request=${{ github.event.pull_request.number }} \
                                 --repo=${{ github.repository }} \
                                 --github-token=${{ secrets.GITHUB_TOKEN }} \
                                 --behavior=update
        env:
          INFRACOST_API_KEY: ${{ secrets.INFRACOST_API_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION || 'us-east-1' }}

  deploy:
    name: Deploy
    runs-on: ubuntu-24.04
    needs: [detect-metadata, synth]
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    environment: dev

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: 'true'
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      # Terraform State Management Setup
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3

      # (Removed DynamoDB lock table step per PR review)

      - name: Bootstrap
        run: ./scripts/bootstrap.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          REPOSITORY: ${{ github.repository }}
          COMMIT_AUTHOR: ${{ github.event.head_commit.author.name || github.actor }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

      - name: Deploy
        run: ./scripts/deploy.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          REPOSITORY: ${{ github.repository }}
          COMMIT_AUTHOR: ${{ github.event.head_commit.author.name || github.actor }}
          TERRAFORM_STATE_BUCKET: ${{ env.TERRAFORM_STATE_BUCKET }}
          TERRAFORM_STATE_BUCKET_REGION: ${{ env.TERRAFORM_STATE_BUCKET_REGION }}
          TERRAFORM_STATE_BUCKET_KEY: ${{ env.ENVIRONMENT_SUFFIX }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}
          CURRENT_ACCOUNT_ID: ${{ env.CURRENT_ACCOUNT_ID }}

      # Note: Deployment outputs are now collected by the deploy.sh script

      - name: Upload Deployment Outputs
        uses: actions/upload-artifact@v4
        with:
          name: cfn-outputs
          path: |
            cfn-outputs/
            cdk-stacks.json
  lint:
    name: Lint
    runs-on: ubuntu-24.04
    needs: [detect-metadata, build]
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    environment: qa
    outputs:
      platform: ${{ needs.detect-metadata.outputs.platform }}
      language: ${{ needs.detect-metadata.outputs.language }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: 'true'
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      # Python setup is handled by the setup-environment action

      - name: Run Linting
        run: ./scripts/lint.sh

  unit-tests:
    name: Unit Testing
    runs-on: ubuntu-24.04
    needs: [detect-metadata, lint]
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    environment: qa

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: 'true'
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Run unit tests
        run: ./scripts/unit-tests.sh

      - name: Prepare coverage reports for Java projects
        if: ${{ needs.detect-metadata.outputs.language == 'java' }}
        run: |
          echo "Preparing Java coverage reports for upload..."
          echo "Debug: Checking current directory structure:"
          ls -la

          echo "Debug: Checking build directory:"
          if [ -d "build" ]; then
            ls -la build/
            if [ -d "build/reports" ]; then
              echo "Reports directory contents:"
              ls -la build/reports/
              if [ -d "build/reports/jacoco" ]; then
                echo "JaCoCo directory contents:"
                find build/reports/jacoco -type f | head -10
              fi
            fi
          else
            echo "No build directory found"
          fi

          mkdir -p coverage

          # Try different possible locations for JaCoCo reports
          if [ -d "build/reports/jacoco/test/" ]; then
            cp -r build/reports/jacoco/test/* coverage/
            echo "✅ Copied JaCoCo reports from build/reports/jacoco/test/ to coverage/ directory"
          elif [ -d "build/reports/jacoco/" ]; then
            cp -r build/reports/jacoco/* coverage/
            echo "✅ Copied JaCoCo reports from build/reports/jacoco/ to coverage/ directory"
          else
            echo "⚠️ JaCoCo reports not found in expected locations"
            # Create a placeholder to avoid upload failure
            echo "No coverage reports generated" > coverage/no-reports.txt
          fi

          echo "Final coverage directory contents:"
          ls -la coverage/
      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            coverage/
            cov.json

  # mocked-integration-tests:
  #   name: Mocked Integration Tests
  #   runs-on: ubuntu-24.04
  #   needs: unit-tests

  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v4

  #     - name: Setup Environment
  #       uses: ./.github/actions/setup-environment
  #       with:
  #         node-version: ${{ env.NODE_VERSION }}
  #         download-artifacts: "true"

  #     - name: Run mocked integration tests
  #       run: npm run test:integration
  #       env:
  #         # Mock environment variables for testing
  #         API_GATEWAY_ENDPOINT: "https://mock-api.example.com/prod"
  #         READ_ONLY_API_KEY: "mock-readonly-key"
  #         ADMIN_API_KEY: "mock-admin-key"

  integration-tests-live:
    name: Integration Tests (Live)
    runs-on: ubuntu-24.04
    needs: [detect-metadata, lint, unit-tests, deploy]
    environment: qa
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: 'true'
          platform: ${{ needs.detect-metadata.outputs.platform }}

      - name: Download Deployment Outputs
        uses: actions/download-artifact@v4
        with:
          name: cfn-outputs
          path: .

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Run integration tests against live environment
        run: ./scripts/integration-tests.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          CI: '1' # Set CI for the entire step
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_CONFIG_PASSPHRASE }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

  claude-code-action:
    runs-on: ubuntu-24.04
    name: 'Claude Review'
    needs: [integration-tests-live]
    permissions:
      contents: write
      pull-requests: write
      issues: write
      id-token: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: refs/pull/${{ github.event.pull_request.number }}/head

      - name: Check for required documentation files
        id: docs-check
        run: |
          if [ ! -f "lib/PROMPT.md" ]; then
            echo "❌ lib/PROMPT.md not found, exiting with failure"
            exit 1
          fi

          if [ ! -f "lib/MODEL_RESPONSE.md" ]; then
            echo "❌ lib/MODEL_RESPONSE.md not found, exiting with failure"
            exit 1
          fi

          if [ ! -f "lib/IDEAL_RESPONSE.md" ]; then
            echo "❌ lib/IDEAL_RESPONSE.md not found, exiting with failure"
            exit 1
          fi

          if [ ! -f "lib/MODEL_FAILURES.md" ]; then
            echo "❌ lib/MODEL_FAILURES.md not found, exiting with failure"
            exit 1
          fi

      - name: Run Claude PR Review Action
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          trigger_phrase: ''
          prompt: |
            CRITICAL: you MUST validate the latest PROMPT file format, and add a comment if it appears to be AI-generated rather than human-written:
            1. Identify all the PROMPT file (PROMPT.md, PROMPT2.md, PROMPT3.md, etc.) - always use the highest numbered one
            2. Read the PROMPT files
            3. Assess whether the content looks human-generated or AI-generated
            4. Look for signs of AI generation such as:
                - Emojis or special symbols (icons) used for formatting
                - Table structures
                - Overly formal or template-like language
                - Logs are allowed when we have multiple prompt files. 
                - Perfect formatting that suggests AI assistance
                - LLM Flavoured text, such as: "Here is a **comprehensive and high-level prompt** for your use..."
            5. If  any PROMPT file appears to be AI-generated rather than human-written, add a comment indicating the issue.
            6. Also validate that for each PROMPT file, there is a corresponding MODEL_RESPONSE file (e.g., PROMPT.md -> MODEL_RESPONSE.md, PROMPT2.md -> MODEL_RESPONSE2.md, etc.) and that it is well-formatted.
            7. PROMPT2.md and PROMPT3.md are optional, but if they exist, they must also be validated and it can contain Deployment/Test/Error logs as well.

            CRITICAL: you MUST validate lib/IDEAL_RESPONSE.md, read .claude/agents/iac-infra-qa-trainer.md to understand how that file should have been created.
            1. Read lib/IDEAL_RESPONSE.md if it exists
            2. lib/IDEAL_RESPONSE.md should be well-formatted, markdown.
            3. Important: There should not be code outside proper code blocks (```python, ```bash, etc.)
            4. Every code file inside lib/ folder should be represented in lib/IDEAL_RESPONSE.md in code_blocks.
            5. There should not be references in the lib/IDEAL_RESPONSE.md to the QA process, unit tests or integration tests.
            6. If the lib/IDEAL_RESPONSE.md does not meet the above criteria, add a comment indicating the issue.

            Follow instructions in .claude/agents/iac-code-reviewer.md. Do not commit any changes, but allow the metadata.json file to be updated.
            Important: The Metadata Enhancement phase in .claude/agents/iac-code-reviewer.md is very important for this project. Make sure that the
            metadata.json file is updated with the fields stated there. If the metadata.json file after the review does not contain the fields:
            - training_quality
            - aws_services
            then add a comment indicating the issue.

            This validation is mandatory and must be completed before any other review activities.
          claude_args: |
            --allowedTools Bash,Read,Write,Edit,MultiEdit,Glob,Grep,LS,Task,TodoWrite

      - name: Upload updated metadata.json
        uses: actions/upload-artifact@v4
        with:
          name: updated-metadata
          path: metadata.json
          if-no-files-found: warn

  cleanup:
    name: Cleanup (Destroy Resources)
    runs-on: ubuntu-24.04
    needs: [detect-metadata, integration-tests-live]
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    environment: stage

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: 'false'
          platform: ${{ needs.detect-metadata.outputs.platform }}
          language: ${{ needs.detect-metadata.outputs.language }}

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Destroy Resources (cleanup any leftover resources)
        run: ./scripts/destroy.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          TERRAFORM_STATE_BUCKET: ${{ env.TERRAFORM_STATE_BUCKET }}
          TERRAFORM_STATE_BUCKET_REGION: ${{ env.TERRAFORM_STATE_BUCKET_REGION }}
          TERRAFORM_STATE_BUCKET_KEY: ${{ env.ENVIRONMENT_SUFFIX }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

  archive-folders:
    name: Archive Folders and Reset Repository
    runs-on: ubuntu-24.04
    needs: [detect-metadata, cleanup]
    environment: release
    if: ${{ github.event_name == 'pull_request' && github.event.action != 'closed' && !contains(github.event.head_commit.message, '[skip-jobs]') }}
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          repository: ${{ github.repository }}
          ref: ${{ github.head_ref }}

      - name: Download coverage reports
        uses: actions/download-artifact@v4
        with:
          name: coverage-reports
          path: coverage/

      - name: Download updated metadata
        uses: actions/download-artifact@v4
        with:
          name: updated-metadata
          path: .

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Archive folders and reset repository
        run: |
          # Configure Git
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"

          # Use metadata from detect-metadata job
          PLATFORM="${{ needs.detect-metadata.outputs.platform }}"
          LANGUAGE="${{ needs.detect-metadata.outputs.language }}"
          echo "Using platform: $PLATFORM, language: $LANGUAGE"

          # Update metadata.json with coverage information and commit author
          # Get commit author from GitHub context
          COMMIT_AUTHOR="${{ github.event.pull_request.user.login || github.actor }}"
          echo "Commit author: $COMMIT_AUTHOR"

          # Extract coverage percentages based on language
          if [ "$LANGUAGE" = "py" ]; then
            echo "Extracting Python coverage from cov.json..."
            if [ -f "cov.json" ]; then
              LINES_COVERAGE=$(jq -r '.totals.percent_covered' cov.json)
              # Calculate branch coverage percentage
              BRANCHES_NUM=$(jq -r '.totals.num_branches' cov.json)
              if [ "$BRANCHES_NUM" = "0" ] || [ "$BRANCHES_NUM" = "null" ]; then
                # No branches to cover, set to 100%
                BRANCHES_COVERAGE=100
              else
                COVERED_BRANCHES=$(jq -r '.totals.covered_branches' cov.json)
                # Calculate percentage: (covered_branches / num_branches) * 100
                BRANCHES_COVERAGE=$(awk "BEGIN {print ($COVERED_BRANCHES / $BRANCHES_NUM) * 100}")
              fi
            else
              echo "Warning: cov.json not found, setting default coverage values"
              LINES_COVERAGE=100
              BRANCHES_COVERAGE=100
            fi
          elif [ "$LANGUAGE" = "go" ]; then
            echo "Extracting Go coverage from coverage-summary.json..."
            if [ -f "coverage/coverage-summary.json" ]; then
              LINES_COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json)
              BRANCHES_COVERAGE=$(jq -r '.total.branches.pct' coverage/coverage-summary.json)
            else
              echo "Warning: Go coverage-summary.json not found, setting default coverage values"
              LINES_COVERAGE=100
              BRANCHES_COVERAGE=100
            fi
          else
            echo "Extracting TypeScript/JavaScript coverage from coverage-summary.json..."
            if [ -f "coverage/coverage-summary.json" ]; then
              LINES_COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json)
              BRANCHES_COVERAGE=$(jq -r '.total.branches.pct' coverage/coverage-summary.json)
            else
              echo "Warning: coverage-summary.json not found, setting default coverage values"
              LINES_COVERAGE=100
              BRANCHES_COVERAGE=100
            fi
          fi

          # If coverage is "Unknown", set to 100
          if [ "$LINES_COVERAGE" = "Unknown" ]; then
            LINES_COVERAGE=100
          fi
          if [ "$BRANCHES_COVERAGE" = "Unknown" ]; then
            BRANCHES_COVERAGE=100
          fi

          echo "Lines coverage: $LINES_COVERAGE%"
          echo "Branches coverage: $BRANCHES_COVERAGE%"

          # Update metadata.json with coverage information and commit author (assuming it always exists)
          jq --arg lines "$LINES_COVERAGE" --arg branches "$BRANCHES_COVERAGE" --arg author "$COMMIT_AUTHOR" '. + {coverage: {lines: ($lines|tonumber), branches: ($branches|tonumber)}, author: $author}' metadata.json > metadata.json.tmp
          mv metadata.json.tmp metadata.json
          echo "Updated metadata.json with coverage information and commit author"

          cat metadata.json

          echo "Current directory contents before archiving:"
          ls -la

          # Get Docker S3 location from the previous step and add it to metadata.json
          DOCKER_S3_LOCATION="${DOCKER_S3_LOCATION}"
          echo "Docker S3 location from previous step: $DOCKER_S3_LOCATION"

          # Add the dockerS3Location to metadata.json
          jq --arg location "$DOCKER_S3_LOCATION" '. + {dockerS3Location: $location}' metadata.json > metadata.json.tmp
          mv metadata.json.tmp metadata.json
          echo "Updated metadata.json with dockerS3Location: $DOCKER_S3_LOCATION"

          # Create archive directory with platform, language, and PR number
          ARCHIVE_DIR="archive/${PLATFORM}-${LANGUAGE}/Pr${{ github.event.number }}"
          mkdir -p "$ARCHIVE_DIR"
          echo "Created archive directory: $ARCHIVE_DIR"

            # Define list of paths to move to archive
            PATHS_TO_ARCHIVE=(
            "lib"
            "bin" 
            "test"
            "tests"
            "cdk.json"
            "metadata.json"
            "tap.py"
            "tap.go"
            "setup.js"
            "cdktf.json"
            "Pulumi.yaml"
            )

          # Move paths to archive
          for path in "${PATHS_TO_ARCHIVE[@]}"; do
          if [[ -d "$path" || -f "$path" ]]; then
            mv "$path" "$ARCHIVE_DIR"/
            echo "Moved $path to archive"
          else
            echo "Path $path not found, skipping"
          fi
          done

          # Check if there are changes to commit
          if git diff --quiet && git diff --cached --quiet; then
            echo "No changes to commit - no folders found to archive"
          else
            git add -A
            git commit -m "Archive build artifacts for PR ${{ github.event.number }} [skip-jobs]"
            git push origin HEAD
            echo "Archive committed to current branch"
          fi

  upload-task-to-s3:
    name: Upload Task to S3
    runs-on: ubuntu-24.04
    environment: release
    if: ${{ github.event_name == 'pull_request' && github.event.pull_request.merged == true }}
    permissions:
      contents: read

    steps:
      - name: Checkout merged code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          repository: ${{ github.repository }}
          ref: ${{ github.event.pull_request.merge_commit_sha }}

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Extract platform and language for S3 upload
        id: extract-metadata
        run: |
          # We need to find the specific archive folder for this PR
          # Since we don't know platform/language yet, we'll search for the PR-specific folder
          PR_FOLDER_PATTERN="archive/*/Pr${{ github.event.number }}"

          # Find the archive folder for this specific PR
          ARCHIVE_FOLDER=""
          for folder in $PR_FOLDER_PATTERN; do
            if [ -d "$folder" ]; then
              ARCHIVE_FOLDER="$folder"
              break
            fi
          done

          if [ -n "$ARCHIVE_FOLDER" ] && [ -f "$ARCHIVE_FOLDER/metadata.json" ]; then
            echo "Found archive folder: $ARCHIVE_FOLDER"
            echo "Found metadata.json at: $ARCHIVE_FOLDER/metadata.json"
            PLATFORM=$(jq -r '.platform // "unknown"' "$ARCHIVE_FOLDER/metadata.json")
            LANGUAGE=$(jq -r '.language // "unknown"' "$ARCHIVE_FOLDER/metadata.json")
          else
            echo "Warning: Could not find archive folder or metadata.json for PR ${{ github.event.number }}"
            echo "Available archive folders:"
            ls -la archive/ || echo "No archive directory found"
            PLATFORM="unknown"
            LANGUAGE="unknown"
          fi
          echo "platform=$PLATFORM" >> $GITHUB_OUTPUT
          echo "language=$LANGUAGE" >> $GITHUB_OUTPUT
          echo "Extracted platform: $PLATFORM, language: $LANGUAGE"

      - name: Upload archive folder to S3
        run: |
          PLATFORM="${{ steps.extract-metadata.outputs.platform }}"
          LANGUAGE="${{ steps.extract-metadata.outputs.language }}"
          S3_PREFIX="${PLATFORM}-${LANGUAGE}/Pr${{ github.event.number }}"

          echo "Uploading archive folder to S3 bucket: ${{ env.S3_RELEASE_BUCKET_NAME }}"
          echo "S3 prefix: $S3_PREFIX"

          # Check if archive folder exists
          if [ -d "archive/${S3_PREFIX}" ]; then
            # Upload the archive folder contents to S3, preserving folder structure
            aws s3 sync "archive/${S3_PREFIX}/" "s3://${{ env.S3_RELEASE_BUCKET_NAME }}/${S3_PREFIX}/" \
              --delete \
              --exclude "*.git*" \
              --exclude "node_modules/*"
            echo "Successfully uploaded archive to S3"
          else
            echo "Archive folder archive/${S3_PREFIX} not found, nothing to upload"
            exit 1
          fi
      - name: Verify S3 upload
        run: |
          PLATFORM="${{ steps.extract-metadata.outputs.platform }}"
          LANGUAGE="${{ steps.extract-metadata.outputs.language }}"
          S3_PREFIX="${PLATFORM}-${LANGUAGE}/Pr${{ github.event.number }}"

          echo "Verifying S3 upload for prefix: $S3_PREFIX"
          aws s3 ls "s3://${{ env.S3_RELEASE_BUCKET_NAME }}/${S3_PREFIX}/" --recursive || echo "No files found or access denied"

  cleanup-pr:
    name: Cleanup (PR Closed)
    runs-on: ubuntu-24.04
    # This job should run regardless of the [skip-jobs] tag since it's for cleanup
    if: github.event_name == 'pull_request' && github.event.action == 'closed' && !github.event.pull_request.merged
    environment: qa

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment
        with:
          node-version: ${{ env.NODE_VERSION }}
          download-artifacts: 'false'

      - name: Configure AWS
        uses: ./.github/actions/configure-aws
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: Destroy Resources (if resources exist)
        run: ./scripts/destroy.sh
        env:
          ENVIRONMENT_SUFFIX: ${{ env.ENVIRONMENT_SUFFIX }}
          TERRAFORM_STATE_BUCKET: ${{ env.TERRAFORM_STATE_BUCKET }}
          TERRAFORM_STATE_BUCKET_REGION: ${{ env.TERRAFORM_STATE_BUCKET_REGION }}
          PULUMI_BACKEND_URL: s3://${{ env.PULUMI_STATE_BUCKET }}?region=${{ env.PULUMI_BUCKET_REGION }}
          PULUMI_ORG: ${{ env.PULUMI_ORG }}

  # TODO: For future use
  # ? Need fine-grained Personal Access Token from repo owner
  # semantic-release:
  #   name: Semantic Release
  #   runs-on: ubuntu-24.04
  #   if: github.event_name == 'push' && github.ref == 'refs/heads/main'
  #   permissions:
  #     contents: write
  #     issues: write
  #     pull-requests: write

  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v4
  #       with:
  #         token: ${{ secrets.GITHUB_TOKEN }}
  #         fetch-depth: 0

  #     - name: Setup Environment
  #       uses: ./.github/actions/setup-environment
  #       with:
  #         node-version: ${{ env.NODE_VERSION }}
  #         download-artifacts: 'false'

  #     - name: Run semantic-release
  #       run: npm run release
  #       env:
  #         GITHUB_TOKEN: ${{ secrets.SEMANTIC_RELEASE_TOKEN }}
