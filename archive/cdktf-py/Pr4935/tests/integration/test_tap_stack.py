"""Live integration checks for the deployed TapStack infrastructure."""
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Iterable, Tuple

import boto3
import pytest
from botocore.exceptions import ClientError, NoCredentialsError


def _load_flat_outputs() -> Dict[str, Dict[str, Any]]:
    """Load the flattened CloudFormation outputs generated by CI."""
    outputs_path = Path(__file__).resolve().parents[2] / "cfn-outputs" / "flat-outputs.json"
    if not outputs_path.exists():
        pytest.skip("flat-outputs.json not found; skip live integration checks.")

    with outputs_path.open(encoding="utf-8") as handle:
        try:
            data = json.load(handle)
        except json.JSONDecodeError as exc:
            pytest.skip(f"Unable to parse flat-outputs.json: {exc}")

    if not isinstance(data, dict) or not data:
        pytest.skip("flat-outputs.json did not contain any stack outputs.")

    # Use the first stack entry by default.
    return data


def _first_stack_outputs() -> Tuple[str, Dict[str, Any]]:
    data = _load_flat_outputs()
    return next(iter(data.items()))


def _ensure_list(value: Any) -> Iterable[str]:
    """Normalize outputs that may be stored as strings or lists."""
    if value is None:
        return []
    if isinstance(value, list):
        return [str(item).strip() for item in value if str(item).strip()]
    if isinstance(value, str):
        trimmed = value.strip().strip("[]")
        if not trimmed:
            return []
        return [item.strip().strip("'\"") for item in trimmed.split(",") if item.strip()]
    return [str(value)]


@pytest.fixture(scope="session")
def deployment_context() -> Dict[str, Any]:
    """Provide the selected stack outputs and AWS region."""
    stack_name, outputs = _first_stack_outputs()
    region = outputs.get("aws_region")
    if not region:
        pytest.skip(f"Stack {stack_name} missing aws_region output.")

    return {"stack_name": stack_name, "region": region, "outputs": outputs}


def _client(service: str, region: str):
    """Create a boto3 client with graceful credential handling."""
    try:
        return boto3.client(service, region_name=region)
    except NoCredentialsError:
        pytest.skip("AWS credentials are not configured for live integration tests.")


def _fetch_required_output(outputs: Dict[str, Any], key: str) -> Any:
    value = outputs.get(key)
    if value in (None, "", [], {}):
        pytest.skip(f"Deployment output '{key}' not present; skipping test.")
    return value


def _describe_with_client(callable_obj, **kwargs):
    try:
        return callable_obj(**kwargs)
    except NoCredentialsError:
        pytest.skip("AWS credentials are not configured for live integration tests.")
    except ClientError as exc:
        pytest.fail(f"AWS API call failed: {exc}")


def test_vpc_and_subnets_exist(deployment_context: Dict[str, Any]):
    outputs = deployment_context["outputs"]
    region = deployment_context["region"]

    vpc_id = _fetch_required_output(outputs, "vpc_id")
    public_subnet_ids = list(_ensure_list(outputs.get("public_subnet_ids")))
    private_subnet_ids = list(_ensure_list(outputs.get("private_subnet_ids")))

    ec2 = _client("ec2", region)
    vpc_resp = _describe_with_client(ec2.describe_vpcs, VpcIds=[vpc_id])
    assert vpc_resp["Vpcs"], f"VPC {vpc_id} was not found."

    all_subnets = public_subnet_ids + private_subnet_ids
    if not all_subnets:
        pytest.skip("No subnet IDs provided in deployment outputs.")

    subnet_resp = _describe_with_client(ec2.describe_subnets, SubnetIds=all_subnets)
    assert len(subnet_resp["Subnets"]) == len(all_subnets)
    assert {subnet["VpcId"] for subnet in subnet_resp["Subnets"]} == {vpc_id}


def test_rds_instance_is_available(deployment_context: Dict[str, Any]):
    outputs = deployment_context["outputs"]
    region = deployment_context["region"]

    db_instance_id = _fetch_required_output(outputs, "rds_instance_id")
    rds_endpoint = outputs.get("rds_endpoint_address")

    rds_client = _client("rds", region)
    response = _describe_with_client(rds_client.describe_db_instances, DBInstanceIdentifier=db_instance_id)

    db_instances = response.get("DBInstances", [])
    assert db_instances, f"RDS instance {db_instance_id} not found."

    status = db_instances[0]["DBInstanceStatus"]
    assert status in {"available", "backing-up", "modifying"}, f"Unexpected RDS status: {status}"


def test_elasticache_serverless_cache_active(deployment_context: Dict[str, Any]):
    outputs = deployment_context["outputs"]
    region = deployment_context["region"]

    cache_name = _fetch_required_output(outputs, "elasticache_name")

    elasticache_client = _client("elasticache", region)
    response = _describe_with_client(
        elasticache_client.describe_serverless_caches,
        ServerlessCacheName=cache_name,
    )

    caches = response.get("ServerlessCaches", [])
    assert caches, f"Serverless cache {cache_name} not found."
    status = caches[0].get("Status")
    assert status in {"available", "modifying", "active"}, f"Unexpected ElastiCache status: {status}"


def test_kms_key_is_enabled(deployment_context: Dict[str, Any]):
    outputs = deployment_context["outputs"]
    region = deployment_context["region"]

    key_arn = _fetch_required_output(outputs, "kms_key_arn")

    kms_client = _client("kms", region)
    response = _describe_with_client(kms_client.describe_key, KeyId=key_arn)

    metadata = response.get("KeyMetadata", {})
    assert metadata.get("KeyState") == "Enabled"


def test_database_secret_exists(deployment_context: Dict[str, Any]):
    outputs = deployment_context["outputs"]
    region = deployment_context["region"]

    secret_arn = _fetch_required_output(outputs, "db_secret_arn")

    secrets_client = _client("secretsmanager", region)
    response = _describe_with_client(secrets_client.describe_secret, SecretId=secret_arn)

    assert response.get("ARN") == secret_arn
