# Payment Processing Platform Observability Infrastructure

## Business Context

Hey, we're building comprehensive monitoring infrastructure for our payment processing platform that handles transactions across three microservices. Following our recent observability audit, we need real-time alerting for transaction failures, API latency spikes, and business metrics tracking to meet our SLA commitments and regulatory compliance requirements. **We'll use Terraform with HCL** to create this monitoring infrastructure in ap-southeast-1.

## Technical Requirements

### KMS Encryption Infrastructure

Create two customer-managed KMS keys—one for encrypting CloudWatch log groups and another for SNS topic encryption. Enable automatic key rotation on both keys for compliance with security policies. Configure comprehensive key policies with multiple statements: first, grant the root account full KMS administrative permissions with Sid "Enable IAM User Permissions" to prevent lockouts; second, allow the CloudWatch Logs service principal (logs.amazonaws.com) to use GenerateDataKey and Decrypt operations with Sid "Allow CloudWatch Logs" for log encryption; third, allow SNS service principal (sns.amazonaws.com) similar permissions with Sid "Allow SNS" for the SNS encryption key. Set deletion_window_in_days to seven on both keys for testing cleanup and create descriptive aliases like "alias/cloudwatch-logs-encryption-dev" and "alias/sns-encryption-dev" for easier reference in resource configurations.

### CloudWatch Log Groups

Set up three separate log groups for the microservices named "/aws/lambda/payment-api-dev", "/aws/lambda/fraud-detection-dev", and "/aws/lambda/notification-service-dev" following CloudWatch Logs naming conventions. Configure each log group with one-day retention for testing purposes and enable KMS encryption using the CloudWatch Logs customer-managed key created above. Add explicit depends_on references to both the KMS key and its alias to handle encryption configuration timing and prevent race conditions during initial deployment. These log groups will receive JSON-formatted application logs containing transaction metadata, error information, response times, and business metrics that'll be parsed by metric filters.

### Lambda Log Generator Functions

Create three Lambda functions in Python 3.11 that simulate the payment processing microservices by generating realistic JSON-formatted logs. The payment-api function generates logs with transaction_id, amount, status_code, response_time_ms, and timestamp fields including simulated errors and latency variations. The fraud-detection function logs risk_score, transaction_id, decision (approve/reject/review), and processing_time_ms with realistic risk distributions. The notification-service function logs notification_type, recipient, delivery_status, and retry_count with occasional failures. Configure each function with 256 MB memory and 60-second timeout. Don't place these Lambda functions in a VPC since they only write to CloudWatch Logs and don't need access to VPC-internal resources, avoiding the VPC Lambda cold start overhead. Package using the archive_file data source and set up EventBridge rules to trigger each function every minute to continuously generate sample logs for monitoring demonstration. Grant CloudWatch Logs write permissions through IAM roles with explicit depends_on for eventual consistency handling.

### Metric Filters and Custom Metrics

Implement metric filters on each log group to extract structured data from the JSON logs and publish custom CloudWatch metrics. For the payment-api log group, create filters extracting error_rate (counting status_code >= 400), average_response_time (from response_time_ms field), and transaction_volume (count of all log events). For fraud-detection, extract high_risk_transaction_count (risk_score > 80) and rejection_rate (decision = "reject"). For notification-service, track delivery_failure_rate and retry_count_total. Configure each metric filter with the appropriate metric_transformation block specifying namespace "PaymentPlatform", metric_name, metric_value from the JSON field, and default_value of zero for periods with no data. These custom metrics enable business KPI tracking and detailed operational monitoring without requiring additional monitoring agents.

### CloudWatch Alarms with Multi-Threshold Monitoring

Create CloudWatch alarms monitoring the custom metrics against defined SLA thresholds with proper alarm actions configured. Set up a critical alarm for payment-api response time exceeding 500 milliseconds averaged over two consecutive one-minute evaluation periods publishing to the critical SNS topic. Configure error rate alarms triggering when the error percentage goes above one percent over a five-minute period to capture sustained issues rather than transient spikes. Implement transaction failure rate monitoring with a threshold of 0.5 percent over three evaluation periods to avoid false positives from single transaction failures. For fraud-detection, create alarms on high-risk transaction spikes (more than 10 high-risk transactions in 5 minutes) and unusual rejection rate patterns (rejection rate above 15 percent). Configure each alarm with appropriate comparison_operator, statistic (Average for latency, Sum for counts, or SampleCount depending on metric type), and treat_missing_data set to "notBreaching" to prevent alerts during low-traffic periods or when services aren't generating logs. Link critical alarms to the critical SNS topic and warning-level alarms to the warnings topic through the alarm_actions parameter.

### SNS Topics and Email Subscriptions

Set up two SNS topics named "sns-payment-alerts-critical-dev" and "sns-payment-alerts-warnings-dev" for different severity levels of operational notifications. Enable KMS encryption on both topics using the SNS customer-managed KMS key with kms_master_key_id parameter. Configure topic policies allowing the CloudWatch Alarms service principal (cloudwatch.amazonaws.com) to publish messages with a statement including Sid "Allow CloudWatch Alarms" and Action "SNS:Publish" restricted to the specific topic ARN. Create email subscriptions on both topics using variables for the email addresses so operations team members can receive alerts—email confirmation will be handled manually outside Terraform as explicitly allowed by framework requirements. The critical topic should be used for immediate-action alerts like sustained high error rates above SLA thresholds or complete service failures, while the warnings topic handles degraded performance and threshold warnings needing investigation but not immediately critical.

### CloudWatch Dashboard

Create a unified CloudWatch dashboard named "payment-platform-monitoring-dev" displaying real-time operational metrics, business KPIs, and system health status in a single pane of glass. Configure the dashboard with multiple widget types using JSON-based dashboard_body configuration: metric widgets showing line graphs of response times and error rates over the past hour with annotations for alarm thresholds, number widgets displaying current transaction counts and success rates as large numeric displays, log insights widgets running pre-configured queries showing recent errors and high-value transactions with automatic refresh, and alarm status widgets showing the current state of all configured alarms color-coded by severity for quick health assessment. Structure the dashboard with logical sections for each microservice (payment-api, fraud-detection, notification-service) plus an overview section with cross-service aggregated metrics. Configure widgets to use appropriate statistics—AVERAGE for latency metrics to show typical response times, SUM for transaction counts to show volume, and MAXIMUM for error spikes to catch peak issues.

### CloudWatch Logs Insights Saved Queries

Configure CloudWatch Logs Insights saved queries for common troubleshooting scenarios that the operations team frequently investigates during incidents. Create a query named "high-value-failed-transactions" using the query definition resource that searches payment-api logs with the pattern "fields @timestamp, transaction_id, amount, status_code, error_message | filter amount > 1000 and status_code >= 400 | sort @timestamp desc" displaying failed high-value transactions sorted by timestamp. Implement a "fraud-detection-rejections" query with pattern "fields @timestamp, transaction_id, risk_score, decision | filter decision = 'reject' | sort risk_score desc" showing all rejected transactions with their risk scores. Add a "notification-delivery-failures" query tracking failed notification attempts with retry counts using filter on delivery_status field. Define a "slow-api-responses" query finding payment-api requests with response_time_ms exceeding 500 milliseconds with the pattern "fields @timestamp, transaction_id, response_time_ms | filter response_time_ms > 500 | sort response_time_ms desc". Store these queries targeting the appropriate log group ARNs so they appear in the CloudWatch Logs Insights console for quick access during troubleshooting.

### IAM Roles and Policies

Create IAM roles for the three Lambda functions following least privilege principles with absolutely no wildcard permissions. Define policies using aws_iam_policy_document data sources granting each Lambda function only the specific permissions needed—CloudWatch Logs CreateLogStream and PutLogEvents actions scoped to the exact log group ARN for that specific function, not wildcard resources or broader permissions. Attach the AWS managed policy "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole" for basic Lambda execution permissions. Configure trust policies with proper assume role statements allowing only the lambda.amazonaws.com service principal to assume these roles with no cross-account or user access. For the EventBridge rules triggering the Lambda functions, create aws_lambda_permission resources granting events.amazonaws.com permission to invoke the specific function ARNs with source_arn set to the EventBridge rule ARN for additional security. Add explicit depends_on relationships from Lambda functions to both the IAM role AND all policy attachments to handle IAM eventual consistency delays that can cause first-apply failures with "cannot assume role" errors.

### EventBridge Scheduling Rules

Set up three EventBridge (CloudWatch Events) rules to trigger the Lambda log generator functions on a regular schedule simulating continuous application activity. Create rules named "eventbridge-payment-api-trigger-dev", "eventbridge-fraud-detection-trigger-dev", and "eventbridge-notification-trigger-dev" with schedule expressions using rate(1 minute) syntax to invoke functions every minute for continuous log generation. Configure each rule's target parameter pointing to the corresponding Lambda function ARN and add aws_lambda_permission resources allowing the EventBridge service to invoke the functions. This scheduled invocation pattern simulates the continuous microservice activity that would occur in a real payment processing platform, generating the log data that metric filters will parse and CloudWatch alarms will monitor for threshold violations.

### S3 Bucket for Log Archival (Optional)

If implementing long-term log archival beyond CloudWatch Logs retention, create an S3 bucket named "s3-cloudwatch-logs-archive-dev-ACCOUNT_ID" using the AWS account ID for global uniqueness. Implement all four public access block settings: block_public_acls, block_public_policy, ignore_public_acls, and restrict_public_buckets all set to true to prevent any public access. Enable versioning for audit trail preservation and configure server-side encryption using the CloudWatch Logs KMS key with server_side_encryption_configuration. Set force_destroy to true for testing cleanup. Add a bucket policy denying unencrypted uploads with a statement using Condition "aws:SecureTransport": "false" to enforce encryption in transit. Configure lifecycle rules with the required filter block transitioning objects to Glacier after 30 days and expiring after 90 days for cost optimization.

## Provider Configuration

Configure Terraform 1.5 or higher with AWS provider version constrained to 5.x using the pessimistic version operator (~> 5.0). Include the random provider version 3.6 for any random value generation and archive provider version 2.4 for Lambda function packaging using the hashicorp/archive source. Deploy all resources to ap-southeast-1 region with default_tags automatically applying Environment set to "dev", Team set to "platform-engineering", CostCenter set to "engineering-ops", ManagedBy set to "terraform", and Project set to "payment-observability" to every resource for cost allocation and governance. Define variables including environment with type string and default value "dev", critical_alert_email with type string for the critical SNS topic subscription, and warnings_alert_email with type string for the warnings topic subscription.

## Resource Naming

Follow the deterministic naming pattern {resource-type}-{purpose}-{environment} for all resources like "kms-logs-encryption-dev", "lambda-payment-api-dev", or "alarm-api-latency-dev" ensuring consistent naming across the infrastructure. CloudWatch log groups use the standard AWS Lambda log group naming convention "/aws/lambda/{function-name}" which CloudWatch Logs automatically associates with Lambda function logging. SNS topics follow "sns-{purpose}-{severity}-{environment}" pattern for clear identification of alert severity. Don't use random_string resources in naming since that causes integration test failures when resource names change unpredictably between applies—use deterministic names only. Keep total resource names under 63 characters to comply with AWS naming limits across all services, particularly important for Lambda functions and CloudWatch alarms.

## Data Source Restrictions

Only use data.aws_caller_identity.current for retrieving the AWS account ID needed for S3 bucket naming and IAM policy principals, data.aws_region.current for the region name in resource configurations and dashboard widgets, data.aws_availability_zones.available if needed for any regional resource distribution although not required for this serverless architecture, and data.archive_file for packaging the three Lambda function source files into deployment ZIP archives. Don't use data sources referencing existing CloudWatch log groups, existing Lambda functions, existing SNS topics, existing KMS keys, or any other pre-existing infrastructure—create all monitoring resources fresh in this configuration following the framework requirement to build everything from scratch.

## File Organization

Structure the configuration with lib/provider.tf containing the Terraform required_version constraint (>= 1.5), required_providers block defining aws (~> 5.0), random (~> 3.6), and archive (~> 2.4) providers, AWS provider configuration with region set to ap-southeast-1 and default_tags block, and all variable definitions including environment, critical_alert_email, and warnings_alert_email with appropriate descriptions and types. The lib/main.tf file contains data sources (caller_identity, region, and three archive_file resources for Lambda packages), two KMS keys with comprehensive policies and aliases, three CloudWatch log groups with encryption, three Lambda functions with their IAM roles and policy attachments, three EventBridge rules with Lambda permissions, metric filters for all custom metrics, CloudWatch alarms for all monitoring thresholds, two SNS topics with email subscriptions and access policies, the CloudWatch dashboard with JSON configuration, CloudWatch Logs Insights saved queries, optional S3 bucket for log archival, and comprehensive outputs with minimum 40-45 outputs covering all resource identifiers and ARNs. Create three separate Python files lib/payment_api.py, lib/fraud_detection.py, and lib/notification_service.py containing the Lambda function handlers with proper logging using Python's json.dumps() for structured JSON log output.

## Cleanup Configuration

Set retention_in_days to one on all CloudWatch log groups for testing instead of the production seven-day retention mentioned in task requirements to minimize storage costs and ensure quick data expiration after testing completes. Configure deletion_window_in_days to seven on both KMS keys (logs encryption and SNS encryption) which is the minimum allowed by AWS. Set force_destroy to true on the optional S3 bucket if created for log archival to allow deletion even with objects present. SNS topics, CloudWatch alarms, metric filters, dashboards, EventBridge rules, Lambda functions, and Logs Insights queries don't require special deletion configuration and will delete cleanly through standard terraform destroy.

## Outputs

Provide comprehensive outputs for all created resources including KMS key IDs and ARNs for both the logs encryption key and SNS encryption key (4 outputs), KMS key alias names (2 outputs), CloudWatch log group names and ARNs for all three microservices (6 outputs), Lambda function names, ARNs, and IAM role ARNs for all three functions (9 outputs), EventBridge rule names and ARNs (6 outputs), metric filter names for all configured custom metrics across the three services (7 outputs), CloudWatch alarm names and ARNs for all threshold monitors (10 outputs), SNS topic names and ARNs for both critical and warnings topics (4 outputs), CloudWatch dashboard name and ARN (2 outputs), CloudWatch Logs Insights query IDs and names (8 outputs), and optional S3 bucket name and ARN if created (2 outputs). Mark the SNS topic ARNs and email subscription endpoints as sensitive since they may contain account information. Tests require these outputs to validate that metric filters are correctly parsing JSON logs from Lambda functions, alarms trigger at the defined thresholds when Lambda functions generate errors or high latency, Lambda functions are successfully writing to CloudWatch Logs, SNS topics are properly configured to receive alarm notifications, and the dashboard displays all configured widgets with live data properly.