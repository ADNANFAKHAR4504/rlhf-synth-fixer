# ECS Microservices Observability Platform

## Business Context

Hey, we're building a comprehensive observability platform for our financial services microservices architecture to meet SLA commitments and regulatory compliance requirements. The DevOps team needs centralized logging with structured metric extraction, distributed tracing across all services, real-time alerting with severity-based routing, and custom business KPI tracking from application logs. **We'll use Terraform with HCL** to create this production-grade monitoring infrastructure in us-east-1.

## Technical Requirements

### Code Documentation Requirements

CRITICAL: All Terraform code must include detailed comment blocks explaining each section's purpose and configuration choices. Use multi-line comments before each resource block describing what the resource does, why specific settings are chosen, and how it integrates with other components. Include inline comments for complex configurations like IAM policies, KMS key policies, metric filter patterns, and EventBridge event patterns. Comment blocks should follow this pattern: start with a description of the resource type, explain the purpose in the architecture, note any dependencies or special considerations, and document security or compliance rationale. This ensures the generated code is self-documenting and maintainable for future infrastructure changes.

### Network Foundation

Create a VPC with CIDR 10.0.0.0/16 containing private subnets for ECS tasks (10.0.1.0/24, 10.0.2.0/24, 10.0.3.0/24) and public subnets for the Application Load Balancer (10.0.11.0/24, 10.0.12.0/24, 10.0.13.0/24) across three availability zones. Deploy three NAT Gateways (one per public subnet with Elastic IPs) for production-grade high availability, enable DNS hostnames and DNS support, and configure route tables so each private subnet routes through its corresponding NAT Gateway while public subnets use an Internet Gateway. Enable VPC Flow Logs capturing all traffic to a dedicated CloudWatch log group with KMS encryption and one-day retention for testing cleanup.

### KMS Encryption Infrastructure

Create three customer-managed KMS keys for CloudWatch Logs encryption, SNS topic encryption, and general application encryption. Each key must enable automatic rotation and include a key policy granting root account full access to prevent lockouts, plus service principals (logs.amazonaws.com for CloudWatch Logs with condition restricting to account log groups, sns.amazonaws.com for SNS topics) with GenerateDataKey and Decrypt permissions. Set deletion_window_in_days to seven for testing cleanup and create aliases like "alias/logs-encryption-dev", "alias/sns-encryption-dev", and "alias/app-encryption-dev" for easier reference.

### ECS Cluster and Microservices

Create an ECS Fargate cluster and deploy three demonstration microservices (auth-service, payment-service, order-service) using the public nginx:latest image from Docker Hub for fully automated deployment without requiring custom container builds. Each service runs as a Fargate task with 512 CPU units and 1024 MB memory, configured with awslogs log driver sending logs to CloudWatch, and an X-Ray daemon sidecar container using the public aws/aws-xray-daemon image for distributed tracing. Define task definitions with execution roles for pulling images and writing logs, plus task roles with permissions to publish X-Ray segments. Deploy one task per service in private subnets with security groups allowing inbound traffic from the Application Load Balancer on port 80 and outbound HTTPS for AWS API calls. Configure nginx containers with environment variables and custom entrypoint commands that write simple JSON-formatted access logs to stdout for metric filter demonstration.

### Application Load Balancer

Set up an internet-facing Application Load Balancer in public subnets with a security group allowing HTTP 80 from the internet for testing. Create target groups for each microservice with health check paths on port 80 using the default nginx health endpoint, deregistration delay of thirty seconds, and sticky sessions disabled. Configure a listener on port 80 forwarding to target groups with path-based routing ("/auth*" to auth-service, "/payment*" to payment-service, "/order*" to order-service with a default action to auth-service), set enable_deletion_protection to false for testing cleanup, and enable access logs to an S3 bucket with AES256 encryption and force_destroy set to true.

### CloudWatch Log Groups and Retention

Create five CloudWatch log groups for all microservices (auth-service, payment-service, order-service, inventory-service, notification-service) even though we're only deploying three ECS services, demonstrating how the observability infrastructure scales independently. Configure each log group with thirty-day retention, KMS encryption using the logs encryption key, and tags for cost allocation including Service, Environment, and CostCenter. Add one additional log group for VPC Flow Logs with one-day retention for testing, and log groups for Lambda functions (also one-day retention). The two non-deployed services (inventory-service, notification-service) will have log groups ready for future service additions.

### X-Ray Tracing Configuration

Configure X-Ray tracing with two custom sampling rules that control what percentage of requests get traced. Create a high-priority rule (priority 100) that samples one hundred percent of requests where the HTTP response status is 5xx or 4xx to capture all error scenarios for troubleshooting. Add a lower-priority rule (priority 200) that samples ten percent of successful requests (2xx status codes) to understand normal operation patterns without excessive tracing costs. Both rules should apply to all services using a wildcard service name pattern and resource ARN matching for the ECS services.

### CloudWatch Metric Filters

Implement metric filters on each of the five log groups to extract metrics from JSON-formatted application logs. Create filters that parse JSON fields using patterns like "{ $.status = * }" for request_count (counting all log entries), "{ $.status >= 400 }" for error_count (counting 4xx and 5xx responses), and extracting numeric values from "$.request_time" for response_time in milliseconds. Each filter publishes to a custom CloudWatch namespace "MicroserviceMetrics" without dimensions (dimensions in metric filters require JSON path selectors from log data). For the three deployed nginx services, the filters will extract basic access log metrics, while the two non-deployed service log groups have filters configured ready for when those services are added. Add filters for business KPI demonstration using patterns like "{ $.payment_amount = * }" and "{ $.order_value = * }" that would extract values when applications write structured business logs.

### CloudWatch Dashboards with Metric Math

Create a comprehensive CloudWatch dashboard with multiple widgets displaying service health and performance. Include line graph widgets showing error_count, response_time, and request_count for each service over the last three hours, a cross-service comparison widget using metric math to calculate error rates with the expression "m1 / m2 * 100" where m1 is error_count and m2 is request_count for all services on one graph, and widgets displaying 95th percentile response times using the metric math PERCENTILE function. Add widgets for custom business metrics demonstrating the patterns for payment volume and order value tracking, plus text widgets explaining that these metrics populate when applications write structured JSON logs. Configure the dashboard with a twelve-hour time range and five-minute period for metric aggregation.

### CloudWatch Composite Alarms

Implement composite alarms that trigger only when multiple conditions are met simultaneously, reducing false positives. Create a composite alarm for each of the three deployed services that triggers when both the error rate exceeds five percent AND the response time exceeds one thousand milliseconds, using alarm rule expressions with AND logic combining the child alarm states like "ALARM(error-rate-auth-dev) AND ALARM(response-time-auth-dev)". Define child alarms for error_count threshold (greater than ten errors in five minutes), response_time threshold (average greater than one thousand milliseconds), and request_rate_drop (less than fifty percent of baseline traffic indicating potential outage). Set composite alarms to trigger SNS notifications only when entering ALARM state, with name prefixes indicating severity level (critical-, warning-, info-) for EventBridge routing.

### Lambda Functions for Custom Business Metrics

Create three Lambda functions in Python 3.11 that process CloudWatch Logs via subscription filters to demonstrate custom business metrics generation patterns. The payment-failure-analyzer function receives payment-service logs, parses JSON to extract payment_method and status fields, calculates failure rates grouped by payment method, and publishes custom metrics to CloudWatch namespace "CustomMetrics/Business". The order-value-tracker function processes order-service logs to calculate average order value and total revenue metrics. The user-action-analytics function parses authentication logs to track login success rates and session patterns. Configure each Lambda with 512 MB memory, three hundred second timeout, environment variables for metric namespace and service name, and subscription filters on the relevant log groups with filter patterns matching JSON log structures. Grant IAM permissions for CloudWatch Logs read access to specific log group ARNs only, CloudWatch PutMetricData for the custom namespace only, and X-Ray tracing with no wildcard permissions. Add explicit depends_on to both IAM role and all policy attachments before Lambda function creation.

### SNS Topics with Severity Levels

Set up three SNS topics for different alert severity levels (critical-alerts, warning-alerts, info-alerts) using KMS encryption with the SNS encryption key. Configure email subscriptions to test addresses (critical@example.com, warning@example.com, info@example.com) which will require manual confirmation but that's acceptable for notification testing per framework rules. Create topic policies allowing CloudWatch Alarms service principal to publish alarm notifications and EventBridge service principal to publish routed events, using specific topic ARN resources with no wildcard permissions. Configure the critical-alerts topic with an SQS dead-letter queue for failed deliveries and enable raw message delivery for integration with external systems like PagerDuty.

### EventBridge Rules for Severity Routing

Create EventBridge rules that route CloudWatch Alarms to appropriate SNS topics based on alarm name prefixes indicating severity levels. Define event patterns matching CloudWatch Alarm state changes where the alarm transitions to ALARM state, with pattern filters checking the alarm name for prefixes "critical-", "warning-", or "info-". Route critical alarms to the critical-alerts SNS topic, warnings to warning-alerts, and informational alarms to info-alerts. Add additional rules that route composite alarms to critical-alerts regardless of name prefix since composite alarms indicate multiple simultaneous issues. Configure rules with descriptions explaining routing logic and input transformers that format alarm details into readable messages including alarm name, state reason, and metric information.

### CloudWatch Anomaly Detection Alarms

Implement CloudWatch anomaly detection alarms for request rate patterns on the request_count metric for each of the three deployed services. Use the ANOMALY_DETECTION_BAND metric math function in CloudWatch alarms (the aws_cloudwatch_anomaly_detector resource type is not available in AWS provider 5.x). Configure alarms with metric queries that compare actual request rates against anomaly detection bands set to two standard deviations from expected values. The alarms trigger when actual request rates fall outside the predicted bands for three consecutive five-minute periods. CloudWatch automatically learns normal traffic patterns including daily and weekly seasonality.

### CloudWatch Insights Queries

Define CloudWatch Insights queries as Terraform output values for common troubleshooting scenarios. Include queries for "Top 10 slowest requests" using syntax "fields @timestamp, @message | filter @message like /request_time/ | sort @message desc | limit 10", "Error messages in last hour" with "fields @timestamp, @message | filter @message like /error|ERROR|Error/ | sort @timestamp desc", "Request distribution by endpoint" parsing URI paths and counting requests, and "Service health overview" aggregating metrics across all services. Format these as multi-line strings ready to paste into CloudWatch Insights console for immediate troubleshooting use.

### Security Groups and IAM Roles

Create security groups for the Application Load Balancer (allowing 80 from internet with egress to ECS tasks), ECS tasks (allowing 80 from ALB security group with egress to 443 for AWS APIs), and VPC endpoints if needed for private AWS service access. Define IAM roles following least privilege including an ECS task execution role with permissions for ECR image pull from public repositories, CloudWatch Logs write to specific log group ARNs, and no Secrets Manager access since we're using public images. Create ECS task roles per service with X-Ray PutTraceSegments for the specific service name only and CloudWatch PutMetricData for custom metrics. Build Lambda execution roles with CloudWatch Logs write, read access to specific source log group ARNs only, PutMetricData for the custom namespace only, and X-Ray tracing. Use aws_iam_policy_document data sources for all policies with explicit resource ARNs and no wildcard permissions except for X-Ray segments which require wildcards. Add explicit depends_on for all role policy attachments before resource usage to handle IAM eventual consistency.

### S3 Bucket for ALB Logs

Create an S3 bucket for Application Load Balancer access logs using the naming pattern "s3-alb-logs-dev-ACCOUNT_ID" for global uniqueness. Enable versioning, configure server-side encryption using AES256 (AWS-managed keys, required for ALB compatibility as ALB cannot write to KMS-encrypted buckets without complex additional configuration), implement all four public access block settings, and set force_destroy to true for testing cleanup. Add a bucket policy granting root account full access first to prevent lockouts, then allowing the ELB service account (using data.aws_elb_service_account) to write logs, and allowing the log delivery service (delivery.logs.amazonaws.com) to write with ACL permissions and perform bucket ACL checks. Configure lifecycle rules with the required filter block (filter with empty prefix to apply to all objects) to transition logs to Glacier after seven days and expire after thirty days.

### SQS Dead Letter Queue

Create an SQS queue for the SNS critical-alerts topic dead-letter queue to capture failed notification deliveries. Configure the queue with KMS encryption using the application encryption key, message retention period of fourteen days for troubleshooting failed deliveries, and visibility timeout of thirty seconds. Set up a queue policy allowing the SNS service principal to send messages with a condition restricting to the critical-alerts topic ARN. Add CloudWatch alarms monitoring the ApproximateNumberOfMessagesVisible metric to alert when failed notifications accumulate in the DLQ.

## Provider Configuration

Configure Terraform 1.5 or higher with AWS provider version constrained to 5.x using pessimistic operator (~> 5.0). Include archive provider version ~> 2.4 for Lambda function packaging using archive_file data source. Deploy all resources to us-east-1 with default_tags applying Environment (dev), CostCenter (devops), ManagedBy (terraform), Compliance (pci-dss), and Owner (platform-team) tags automatically. Define variables with type constraints for environment (string, default "dev"), retention_days (number, default 30), service_names (list of strings with the five microservice names), and alarm_thresholds (map of numbers for configurable alerting with keys like error_rate_percent and response_time_ms).

## Resource Naming

Follow the deterministic naming pattern {resource-type}-{purpose}-{environment} for all resources like "log-group-auth-service-dev", "alarm-error-rate-payment-dev", or "lambda-payment-analyzer-dev". S3 buckets need AWS account ID appended for global uniqueness like "s3-alb-logs-dev-ACCOUNT_ID" using data.aws_caller_identity.current.account_id. CloudWatch namespaces use "MicroserviceMetrics/dev" and "CustomMetrics/Business/dev" patterns with environment suffix. Don't use random_string resources in naming since that causes integration test failures with dynamic resource discovery.

## Data Source Restrictions

Only use data.aws_caller_identity.current for account ID in resource names and ARNs, data.aws_region.current for region name in policies and conditions, data.aws_availability_zones.available for subnet distribution across AZs, data.aws_elb_service_account.main for ALB logging bucket policy, and data.archive_file.lambda_zip for packaging Lambda functions from inline Python code. Don't use data sources referencing existing infrastructure like existing VPCs, subnets, security groups, or ECS clustersâ€”create all networking and compute resources fresh.

## File Organization

Structure with lib/provider.tf containing Terraform and provider version constraints (terraform, aws, archive), AWS provider configuration with default_tags block, and all variable definitions (environment, retention_days, service_names, alarm_thresholds). Create lib/main.tf containing data sources and all infrastructure resources including VPC networking (vpc, subnets, route tables, three NAT gateways, internet gateway, security groups), KMS keys and aliases, S3 bucket for ALB logs with bucket policy and lifecycle rules, SQS queue for SNS DLQ, ECS cluster and three task definitions using nginx:latest and aws-xray-daemon public images, ECS services with ALB target group attachments, Application Load Balancer with target groups and listener rules, IAM roles and policies for ECS execution, ECS tasks, and Lambda functions, CloudWatch log groups for all five services plus VPC Flow Logs and Lambda, X-Ray sampling rules, metric filters for all five services, dashboards with metric math widgets, individual child alarms, composite alarms, anomaly detection alarms, three SNS topics with subscriptions and policies, EventBridge rules with event patterns and input transformers, three Lambda functions with subscription filters, and comprehensive outputs. Create three Lambda function files: lib/payment_failure_analyzer.py, lib/order_value_tracker.py, and lib/user_action_analytics.py containing Python 3.11 handlers that parse JSON logs and publish custom CloudWatch metrics using boto3.

## Cleanup Configuration

Set force_destroy to true on the S3 bucket for ALB logs, deletion_window_in_days to seven on all three KMS keys, retention_in_days to one on VPC Flow Logs and Lambda log groups (thirty days on the five microservice log groups per requirements), enable_deletion_protection to false on the Application Load Balancer, and force_delete to true on ECS services. CloudWatch resources (alarms, dashboards, metric filters, anomaly detection alarms) delete cleanly without special configuration, SNS topics and EventBridge rules delete immediately once subscriptions are removed, and the SQS DLQ deletes cleanly. All three NAT Gateways will delete in 2-3 minutes each, and ECS services drain and delete within 5 minutes.

## Integration Testing Outputs

Provide comprehensive outputs for validation including CloudWatch log group names and ARNs for all five services plus VPC Flow Logs and three Lambda functions (sixteen outputs), KMS key IDs and ARNs for all three keys (six outputs), SNS topic ARNs and names for all severity levels (six outputs), Lambda function names, ARNs, and role ARNs for all three functions (nine outputs), ECS cluster ID, three service names, and task definition ARNs (seven outputs), Application Load Balancer DNS name and ARN plus three target group ARNs (five outputs), VPC ID, six subnet IDs, and three NAT Gateway IDs (ten outputs), S3 bucket name and ARN (two outputs), SQS DLQ URL and ARN (two outputs), CloudWatch dashboard name and URL (two outputs), composite alarm names for the three services (three outputs), EventBridge rule names and ARNs for the three severity routing rules (six outputs), X-Ray sampling rule IDs (two outputs), and CloudWatch Insights query strings for all troubleshooting scenarios (five outputs). Mark ALB DNS name as sensitive and include descriptions explaining each output's testing purpose with minimum seventy-five total outputs for comprehensive validation.
