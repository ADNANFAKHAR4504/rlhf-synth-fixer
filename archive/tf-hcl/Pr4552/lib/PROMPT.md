Hey, I need to set up an EC2 instance for hosting a web application in us-west-2. We're going with a t3.medium instance since that's got enough resources for our app without being overkill. The instance needs to run on the latest Amazon Linux 2 AMI, so use a data source to grab whatever's current - I don't want to hardcode AMI IDs and have them go stale. Make sure the instance is launched in us-west-2a specifically, since we need everything in a single availability zone for this setup.

For storage, I need an 80GB gp3 EBS volume attached to the instance for application data. The volume has to be encrypted using AWS managed keys - nothing fancy with custom KMS keys needed here, just the default encryption that AWS provides. Oh and this is important: the EBS volume needs deletion protection enabled because we can't afford to accidentally lose application data. The volume should be configured as a separate resource and attached to the instance, not just the root volume.

Security-wise, we need to be pretty locked down. Create a security group that only allows SSH on port 22 and HTTPS on port 443, and both should only accept traffic from the 10.0.0.0/8 CIDR range. Don't open this up to the internet - that's our internal network range and that's all that needs access. Each security group rule needs a description explaining what it's for, so make those clear. The instance also needs to use IMDSv2 for the metadata service - that's the newer, more secure version and it's required for our compliance standards. For access management, the user data script should install and start the SSM agent so we can manage the instance through Systems Manager without needing to mess with SSH keys all the time.

For the networking setup, the instance needs a static private IP address within a /24 subnet. I'm thinking we'll need to create a VPC with a subnet that has a /24 CIDR block, then assign the instance a private IP from that range. Since this is all internal, we don't need an internet gateway or public IPs - just keep everything private and secure.

Now for backups, this is critical - we need automated EBS snapshots running daily at 2 AM UTC. Set this up using AWS Data Lifecycle Manager with a policy that creates snapshots of the application data volume every day at that time. We'll want to keep snapshots for a reasonable retention period, maybe 7 days or so, to balance cost with recovery options.

For file organization, just put everything in main.tf. I mean everything - the terraform and provider blocks at the top, then data sources for getting the latest AMI, then variables for things like region and instance type, then locals for common_tags and reusable config, then a random_string resource for unique naming (8 chars, no special chars, lowercase only), then the VPC and networking resources, then the EC2 instance and EBS volume, then the DLM policy for snapshots, and finally all the outputs at the bottom. Keep it all in one file, it's easier to manage.

Oh and make sure all resource names use lowercase letters and hyphens only - no underscores or capital letters in the actual resource names. Every resource needs a Name tag following the pattern 'webapp-{resource-type}', so like 'webapp-instance', 'webapp-volume', 'webapp-security-group', etc. Use the common_tags pattern and merge in resource-specific tags.

For outputs, I need the instance ID and the private IP address. These should be clearly labeled so they're easy to grab for integration testing or when we need to reference them in other configurations.

Let me know if anything's unclear or if you need more details about any of this!