Hey, I'm setting up infrastructure for a blog platform that needs to handle around 5,000 daily readers, but we're expecting some pretty significant traffic spikes - you know how it goes when a post goes viral or gets picked up by a news aggregator. I need a web infrastructure that can auto-scale based on demand and provide basic performance monitoring so we're not flying blind.

So basically, I need a VPC set up with a 10.0.0.0/16 CIDR block. Within that VPC, create public subnets across at least two availability zones for high availability - let's say 10.0.1.0/24 and 10.0.2.0/24. We'll need an internet gateway attached to the VPC so our instances can reach the outside world, and route tables configured to send traffic through that gateway. For the compute layer, I'm thinking an Auto Scaling Group running t3.micro instances - they're cost-effective and should handle our traffic patterns just fine. Put an Application Load Balancer in front of the ASG to distribute HTTP traffic evenly across instances. The ALB should be internet-facing and listen on port 80.

For security, we need tight security groups. Create one for the ALB that allows inbound HTTP traffic on port 80 from anywhere (0.0.0.0/0), but only allows outbound traffic to the EC2 security group. Then create a separate security group for the EC2 instances that only allows inbound traffic on port 80 from the ALB security group - that way, instances aren't directly exposed to the internet. All outbound traffic from instances should be allowed so they can pull updates and communicate with AWS services. For IAM, the EC2 instances need a role with permissions to send metrics and logs to CloudWatch, plus SSM access would be nice for troubleshooting without SSH. Make sure the instance profile is attached to the launch template.

So for monitoring and auto-scaling, I need CloudWatch alarms that trigger scaling actions. When average CPU utilization across the ASG goes above 70% for two consecutive 5-minute periods, scale out by adding one instance. When CPU drops below 30% for 10 minutes, scale in by removing one instance. Also set up an alarm for request count - if the ALB is seeing more than 1,000 requests per minute, that should trigger a scale-out event too. The ASG should start with a minimum of 2 instances for redundancy, scale up to a maximum of 6 instances during spikes, and maintain a desired capacity of 2 under normal conditions. Health checks should use the ALB's target group health - if an instance fails three consecutive checks, replace it automatically.

For file organization, split it into two files under the lib/ directory. Put the Terraform and provider configuration blocks in lib/provider.tf - that's just the terraform block with required providers and the provider "aws" blocks with regions and default tags. Everything else goes in lib/main.tf - data sources for getting account ID and region, then variables, then locals for common_tags and reusable config, then a random_string resource for unique naming (8 chars, no special chars, lowercase only), then all the infrastructure resources organized with clear comment headers starting with VPC, then subnets, then internet gateway, then route tables, then security groups, then IAM role and instance profile, then launch template, then ALB and target group, then ASG, then CloudWatch alarms, and finally all the outputs at the bottom.

Oh and make sure to use AWS provider version 5.0 or higher since we need the latest resource patterns. Deploy everything to us-west-1 by default, but make the region configurable via a variable. All resource names should include a random suffix so we can deploy multiple environments without conflicts. Instance names should be tagged with their environment and the ASG name so we can track them easily.

For testing purposes, I'll need outputs for the ALB DNS name (that's our main endpoint), the VPC ID, subnet IDs, security group IDs, ASG name, and the ARNs for the CloudWatch alarms. That'll let me verify everything's connected properly and actually serving traffic.

Let me know if anything's unclear.