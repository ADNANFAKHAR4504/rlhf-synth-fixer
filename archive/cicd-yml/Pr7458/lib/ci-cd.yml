version: 2.1

orbs:
  gcp-cli: circleci/gcp-cli@3.1
  gcp-gcr: circleci/gcp-gcr@0.16
  kubernetes: circleci/kubernetes@1.3
  node: circleci/node@5.1
  python: circleci/python@2.1

parameters:
  gcp-project-id:
    type: string
  environment:
    type: enum
    enum: [dev, staging, prod]
    default: dev
  gke-cluster:
    type: string
    default: payments-gke-cluster

executors:
  node-app-executor:
    docker:
      - image: ${PRIVATE_REGISTRY}/node:20-bullseye
    working_directory: ~/project

  python-executor:
    docker:
      - image: ${PRIVATE_REGISTRY}/python:3.11-slim
    working_directory: ~/project

  gcloud-executor:
    docker:
      - image: ${PRIVATE_REGISTRY}/google/cloud-sdk:alpine
    working_directory: ~/project

  machine-executor:
    machine:
      image: ubuntu-2204:current
    working_directory: ~/project

commands:
  auth-gcp:
    description: "Authenticate to GCP using Workload Identity Federation"
    steps:
      - gcp-cli/setup:
          project-id: << pipeline.parameters.gcp-project-id >>
          workload-identity-provider: ${WORKLOAD_IDENTITY_PROVIDER}
          service-account-email: ${GCP_SERVICE_ACCOUNT_EMAIL}

  install-tools:
    description: "Install kubectl, helm, skaffold, and Cloud SQL Proxy"
    steps:
      - run:
          name: Install tooling
          command: |
            set -eo pipefail
            if command -v apk >/dev/null 2>&1; then
              apk add --no-cache curl bash jq
            elif command -v apt-get >/dev/null 2>&1; then
              sudo apt-get update
              sudo apt-get install -y curl bash jq
            fi
            curl -sLO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
            chmod +x kubectl && sudo mv kubectl /usr/local/bin/
            curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
            curl -sLo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64
            chmod +x skaffold && sudo mv skaffold /usr/local/bin/
            curl -sLo cloud-sql-proxy https://storage.googleapis.com/cloud-sql-connectors/cloud-sql-proxy/latest/cloud-sql-proxy.linux.amd64
            chmod +x cloud-sql-proxy && sudo mv cloud-sql-proxy /usr/local/bin/

jobs:
  validate-python:
    executor: python-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: << pipeline.parameters.environment >>
    steps:
      - checkout
      - python/install-packages:
          pkg-manager: poetry
      - run:
          name: Run pylint
          command: |
            mkdir -p lint-results/python
            poetry run pylint payment-processor fraud-detector | tee lint-results/python/pylint.txt
      - run:
          name: Run mypy
          command: |
            poetry run mypy payment-processor fraud-detector | tee lint-results/python/mypy.txt
      - run:
          name: Run bandit
          command: |
            poetry run bandit -r payment-processor fraud-detector | tee lint-results/python/bandit.txt
      - run:
          name: Run black check
          command: |
            poetry run black --check payment-processor fraud-detector | tee lint-results/python/black.txt
      - store_artifacts:
          path: lint-results
          destination: lint-results/python

  validate-node:
    executor: node-app-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: << pipeline.parameters.environment >>
    steps:
      - checkout
      - node/install-packages
      - run:
          name: Run ESLint
          command: |
            mkdir -p lint-results/node
            npx eslint api-gateway merchant-portal | tee lint-results/node/eslint.txt
      - run:
          name: Run TypeScript compiler
          command: |
            npx tsc -p tsconfig.json | tee lint-results/node/tsc.txt
      - store_artifacts:
          path: lint-results
          destination: lint-results/node

  validate-infrastructure:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: << pipeline.parameters.environment >>
    steps:
      - checkout
      - run:
          name: Terraform fmt
          command: terraform fmt -check
      - run:
          name: Terraform validate
          command: terraform validate
      - run:
          name: Run tflint
          command: tflint
      - run:
          name: Run Checkov (Terraform + PCI-DSS)
          command: |
            mkdir -p infra-validation
            checkov -d . --framework terraform --check PCI-DSS | tee infra-validation/checkov.txt
      - store_artifacts:
          path: infra-validation
          destination: infra-validation

  scan-vulnerabilities:
    executor: python-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - run:
          name: Safety - Python dependency scan
          command: |
            mkdir -p security-scans
            safety check -r requirements.txt | tee security-scans/safety-python.txt
      - run:
          name: npm audit - Node dependency scan
          command: |
            npm install
            npm audit --audit-level=high | tee security-scans/npm-audit.txt
      - run:
          name: Trivy filesystem scan
          command: |
            trivy fs . --security-checks vuln,config --format table | tee security-scans/trivy-fs.txt
      - store_artifacts:
          path: security-scans
          destination: security-scans

  build-python-services:
    executor: machine-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Enable Docker Buildx
          command: |
            docker buildx create --use --name payments-builder || docker buildx use payments-builder
      - run:
          name: Build payment-processor image
          command: |
            docker buildx build               -t ${GCP_PROJECT_ID}.pkg.dev/payments/images/payment-processor:${CIRCLE_SHA1}               -f services/payment-processor/Dockerfile               --platform linux/amd64               services/payment-processor
      - run:
          name: Build fraud-detector image
          command: |
            docker buildx build               -t ${GCP_PROJECT_ID}.pkg.dev/payments/images/fraud-detector:${CIRCLE_SHA1}               -f services/fraud-detector/Dockerfile               --platform linux/amd64               services/fraud-detector
      - gcp-gcr/push-image:
          image: ${GCP_PROJECT_ID}.pkg.dev/payments/images/payment-processor:${CIRCLE_SHA1}
      - gcp-gcr/push-image:
          image: ${GCP_PROJECT_ID}.pkg.dev/payments/images/fraud-detector:${CIRCLE_SHA1}
      - run:
          name: Trivy image scan (block on CRITICAL)
          command: |
            mkdir -p sbom
            for image in payment-processor fraud-detector; do
              FULL_IMAGE="${GCP_PROJECT_ID}.pkg.dev/payments/images/${image}:${CIRCLE_SHA1}"
              trivy image --exit-code 1 --severity CRITICAL --format table "$FULL_IMAGE" | tee "sbom/trivy-${image}.txt"
              trivy image --format cyclonedx --output "sbom/${image}-sbom.json" "$FULL_IMAGE"
            done
      - store_artifacts:
          path: sbom
          destination: sbom

  build-node-services:
    executor: machine-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Build api-gateway image
          command: |
            docker build               -t ${GCP_PROJECT_ID}.pkg.dev/payments/images/api-gateway:${CIRCLE_SHA1}               -f services/api-gateway/Dockerfile               services/api-gateway
      - run:
          name: Build merchant-portal image
          command: |
            docker build               -t ${GCP_PROJECT_ID}.pkg.dev/payments/images/merchant-portal:${CIRCLE_SHA1}               -f services/merchant-portal/Dockerfile               services/merchant-portal
      - gcp-gcr/push-image:
          image: ${GCP_PROJECT_ID}.pkg.dev/payments/images/api-gateway:${CIRCLE_SHA1}
      - gcp-gcr/push-image:
          image: ${GCP_PROJECT_ID}.pkg.dev/payments/images/merchant-portal:${CIRCLE_SHA1}
      - run:
          name: Grype container scan
          command: |
            mkdir -p container-scans
            for image in api-gateway merchant-portal; do
              FULL_IMAGE="${GCP_PROJECT_ID}.pkg.dev/payments/images/${image}:${CIRCLE_SHA1}"
              grype "$FULL_IMAGE" | tee "container-scans/grype-${image}.txt"
            done
      - run:
          name: Cosign sign images with KMS
          command: |
            for image in api-gateway merchant-portal; do
              FULL_IMAGE="${GCP_PROJECT_ID}.pkg.dev/payments/images/${image}:${CIRCLE_SHA1}"
              cosign sign --key "${COSIGN_KMS_KEY}" "$FULL_IMAGE"
            done
      - store_artifacts:
          path: container-scans
          destination: container-scans

  unit-test-python:
    executor: python-executor
    parallelism: 3
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - python/install-packages:
          pkg-manager: poetry
      - run:
          name: Run pytest with coverage
          command: |
            mkdir -p test-results/python
            mkdir -p coverage
            TEST_FILES=$(circleci tests glob "tests/python/unit/**/*.py" | circleci tests split)
            poetry run pytest $TEST_FILES               --cov=payment-processor --cov=fraud-detector               --cov-report=xml:coverage/coverage-python.xml               --junitxml=test-results/python/junit.xml
      - store_test_results:
          path: test-results/python
      - store_artifacts:
          path: coverage
          destination: coverage/python

  unit-test-node:
    executor: node-app-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - node/install-packages
      - run:
          name: Run Jest with coverage
          command: |
            mkdir -p test-results/node
            mkdir -p coverage
            npx jest --ci --coverage --coverageReporters=json-summary,cobertura --runInBand               --outputFile=test-results/node/jest-results.json
      - store_test_results:
          path: test-results/node
      - store_artifacts:
          path: coverage
          destination: coverage/node

  integration-test:
    executor: machine-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Start emulators and proxies (docker-compose)
          command: |
            docker-compose -f infra/docker-compose.integration.yml up -d
      - run:
          name: Run Python integration tests
          command: |
            mkdir -p test-results/integration
            poetry install
            poetry run pytest tests/python/integration               --junitxml=test-results/integration/python-integration.xml
      - run:
          name: Run Node API integration tests
          command: |
            npm install
            npx jest --config jest.integration.config.js               --runInBand               --outputFile=test-results/integration/node-integration.json
      - run:
          name: Run Pact contract tests
          command: |
            mkdir -p pact-contracts
            npm run pact:test
            cp -r pact/contracts pact-contracts/ || true
      - store_test_results:
          path: test-results/integration
      - store_artifacts:
          path: pact-contracts
          destination: pact-contracts

  security-sast:
    executor: machine-executor
    steps:
      - checkout
      - run:
          name: Run Semgrep (PCI-DSS ruleset)
          command: |
            mkdir -p sast-reports
            semgrep --config "p/owasp-top-ten,p/PCI-DSS" . | tee sast-reports/semgrep.txt
      - run:
          name: Run CodeQL (Python & JavaScript)
          command: |
            codeql database create codeql-db               --language=python,python3,javaScript               --source-root=.
            codeql database analyze codeql-db               --format=sarifv2.1.0               --output=sast-reports/codeql.sarif
      - run:
          name: Run Gitleaks
          command: |
            gitleaks detect --no-banner --redact --report-format json --report-path sast-reports/gitleaks.json
      - run:
          name: Run Checkov on Kubernetes manifests
          command: |
            checkov -d k8s/ --framework kubernetes | tee sast-reports/checkov-k8s.txt
      - store_artifacts:
          path: sast-reports
          destination: sast-reports

  security-secrets:
    executor: gcloud-executor
    steps:
      - checkout
      - run:
          name: Run TruffleHog
          command: |
            mkdir -p secret-scans
            trufflehog filesystem . --fail --json | tee secret-scans/trufflehog.json
      - run:
          name: Run detect-secrets
          command: |
            detect-secrets scan . > secret-scans/detect-secrets.json
            detect-secrets audit secret-scans/detect-secrets.json || true
      - store_artifacts:
          path: secret-scans
          destination: secret-scans

  pci-compliance:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Run Prowler PCI-DSS checks
          command: |
            mkdir -p compliance
            prowler -g pci -M json -o compliance/prowler-pci
      - run:
          name: Run custom PCI controls validation
          command: |
            chmod +x scripts/validate-pci-controls.sh
            scripts/validate-pci-controls.sh | tee compliance/custom-pci-controls.txt
      - store_artifacts:
          path: compliance
          destination: compliance

  performance-test:
    executor: machine-executor
    resource_class: xlarge
    steps:
      - checkout
      - run:
          name: k6 cloud payment load test
          command: |
            mkdir -p perf-results
            k6 run --out cloud perf/k6/payment-load-test.js | tee perf-results/k6.txt
      - run:
          name: Artillery sustained load test
          command: |
            npx artillery run perf/artillery/spanner-sustained.yml | tee perf-results/artillery.txt
      - store_artifacts:
          path: perf-results
          destination: perf-results

  load-test-spanner:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Spanner load test
          command: |
            mkdir -p spanner-load
            chmod +x scripts/spanner-load-test.sh
            scripts/spanner-load-test.sh | tee spanner-load/spanner-load.txt
      - store_artifacts:
          path: spanner-load
          destination: spanner-load

  deploy-dev:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: dev
      GKE_CLUSTER: << pipeline.parameters.gke-cluster >>
    steps:
      - checkout
      - auth-gcp
      - install-tools
      - run:
          name: Terraform apply (dev)
          command: |
            cd infra/terraform
            terraform workspace select dev || terraform workspace new dev
            terraform apply -auto-approve
      - run:
          name: Skaffold deploy to dev GKE cluster
          command: |
            gcloud container clusters get-credentials "${GKE_CLUSTER}" --zone=us-central1-a --project="${GCP_PROJECT_ID}"
            skaffold deploy -p dev
      - run:
          name: Run database migrations (Alembic)
          command: |
            cd services/payment-processor
            alembic upgrade head
      - run:
          name: Configure Cloud HSM
          command: |
            chmod +x scripts/configure-hsm.sh
            scripts/configure-hsm.sh
      - store_artifacts:
          path: deploy
          destination: deploy/dev

  smoke-test-dev:
    executor: node-app-executor
    environment:
      ENVIRONMENT: dev
    steps:
      - checkout
      - run:
          name: Run Newman smoke tests
          command: |
            mkdir -p test-results/smoke-dev
            newman run postman/collections/payments-smoke.json               --environment postman/environments/dev.postman_environment.json               --reporters cli,junit               --reporter-junit-export test-results/smoke-dev/newman.xml
      - run:
          name: Test HSM integration
          command: |
            chmod +x scripts/test-hsm-integration.sh
            scripts/test-hsm-integration.sh
      - store_test_results:
          path: test-results/smoke-dev

  deploy-staging-infrastructure:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: staging
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Terraform apply (staging multi-region)
          command: |
            cd infra/terraform
            terraform workspace select staging || terraform workspace new staging
            terraform apply -auto-approve -var="gke_regions=us-central1,europe-west1"
      - run:
          name: Configure VPC Service Controls perimeter
          command: |
            echo "Configuring VPC Service Controls for PCI zones..."
      - store_artifacts:
          path: deploy
          destination: deploy/staging

  canary-staging:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: staging
    steps:
      - checkout
      - auth-gcp
      - install-tools
      - run:
          name: Deploy canary with Flagger
          command: |
            mkdir -p canary-metrics
            chmod +x scripts/deploy-canary-flagger.sh
            scripts/deploy-canary-flagger.sh | tee canary-metrics/flagger.txt
      - store_artifacts:
          path: canary-metrics
          destination: canary-metrics

  integration-test-staging:
    executor: machine-executor
    steps:
      - checkout
      - run:
          name: Comprehensive API tests (Postman)
          command: |
            mkdir -p test-results/staging
            newman run postman/collections/payments-api-regression.json               --environment postman/environments/staging.postman_environment.json               --reporters cli,junit               --reporter-junit-export test-results/staging/postman.xml
      - run:
          name: Payment gateway integration tests
          command: |
            npm install
            npm run test:gateway:staging | tee test-results/staging/gateway.txt
      - run:
          name: Fraud detection accuracy tests
          command: |
            poetry install
            poetry run pytest tests/python/fraud_accuracy               --junitxml=test-results/staging/fraud-accuracy.xml
      - run:
          name: Spanner data consistency tests
          command: |
            poetry run pytest tests/python/spanner_consistency               --junitxml=test-results/staging/spanner-consistency.xml
      - store_test_results:
          path: test-results/staging
      - store_artifacts:
          path: test-results/staging
          destination: test-results/staging

  e2e-pci-validation:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: staging
    steps:
      - checkout
      - auth-gcp
      - run:
          name: OWASP ZAP PCI ASV scan
          command: |
            mkdir -p security-e2e
            ./scripts/run-zap-pci-scan.sh | tee security-e2e/zap-asv.txt
      - run:
          name: nmap network scan
          command: |
            nmap -sV -Pn payments-staging.example.com | tee security-e2e/nmap.txt
      - run:
          name: sslyze TLS configuration validation
          command: |
            sslyze --regular payments-staging.example.com | tee security-e2e/sslyze.txt
      - run:
          name: Test cardholder data encryption
          command: |
            chmod +x scripts/test-cardholder-data-encryption.sh
            scripts/test-cardholder-data-encryption.sh | tee security-e2e/cardholder-encryption.txt
      - run:
          name: Validate tokenization
          command: |
            chmod +x scripts/validate-tokenization.sh
            scripts/validate-tokenization.sh | tee security-e2e/tokenization.txt
      - store_artifacts:
          path: security-e2e
          destination: security-e2e

  dast-testing:
    executor: machine-executor
    steps:
      - checkout
      - run:
          name: Run custom DAST suite
          command: |
            mkdir -p dast-reports
            chmod +x scripts/run-payment-dast.sh
            scripts/run-payment-dast.sh | tee dast-reports/dast.txt
      - store_artifacts:
          path: dast-reports
          destination: dast-reports

  compliance-validation:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
    steps:
      - checkout
      - auth-gcp
      - run:
          name: PCI-DSS validation script
          command: |
            mkdir -p compliance-final
            chmod +x scripts/pci-dss-validation.sh
            scripts/pci-dss-validation.sh | tee compliance-final/pci-dss.txt
      - run:
          name: Validate audit logs
          command: |
            chmod +x scripts/validate-audit-logs.sh
            scripts/validate-audit-logs.sh | tee compliance-final/audit-logs.txt
      - run:
          name: Check network segmentation
          command: |
            chmod +x scripts/check-network-segmentation.sh
            scripts/check-network-segmentation.sh | tee compliance-final/network-segmentation.txt
      - store_artifacts:
          path: compliance-final
          destination: compliance-final

  blue-green-production:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: prod
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Terraform apply (prod multi-region)
          command: |
            cd infra/terraform
            terraform workspace select prod || terraform workspace new prod
            terraform apply -auto-approve -var="gke_regions=us-central1,us-east1,europe-west1,asia-northeast1"
      - run:
          name: Blue-green deployment to all regions
          command: |
            mkdir -p deploy/prod
            chmod +x scripts/deploy-blue-green.sh
            scripts/deploy-blue-green.sh | tee deploy/prod/blue-green.txt
      - store_artifacts:
          path: deploy/prod
          destination: deploy/prod

  smoke-test-production:
    executor: node-app-executor
    environment:
      ENVIRONMENT: prod
    steps:
      - checkout
      - run:
          name: Critical path smoke tests
          command: |
            mkdir -p test-results/prod-smoke
            newman run postman/collections/payments-smoke.json               --environment postman/environments/prod.postman_environment.json               --reporters cli,junit               --reporter-junit-export test-results/prod-smoke/newman.xml
      - run:
          name: Regional failover tests
          command: |
            npm install
            npm run test:failover:prod | tee test-results/prod-smoke/failover.txt
      - run:
          name: Synthetic transactions
          command: |
            npm run test:synthetic:prod | tee test-results/prod-smoke/synthetic.txt
      - store_test_results:
          path: test-results/prod-smoke
      - store_artifacts:
          path: test-results/prod-smoke
          destination: test-results/prod-smoke

  setup-monitoring:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: prod
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Configure Cloud Monitoring dashboards & SLOs
          command: |
            mkdir -p monitoring
            chmod +x scripts/configure-monitoring.sh
            scripts/configure-monitoring.sh | tee monitoring/monitoring.txt
      - run:
          name: Configure logging & SIEM sinks
          command: |
            chmod +x scripts/configure-logging.sh
            scripts/configure-logging.sh | tee monitoring/logging.txt
      - run:
          name: Setup incident response integration
          command: |
            chmod +x scripts/setup-incident-response.sh
            scripts/setup-incident-response.sh | tee monitoring/incident-response.txt
      - store_artifacts:
          path: monitoring
          destination: monitoring

  production-validation:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: prod
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Production health checks
          command: |
            mkdir -p prod-validation
            chmod +x scripts/production-health-check.sh
            scripts/production-health-check.sh | tee prod-validation/health-check.txt
      - run:
          name: Verify PCI compliance in prod
          command: |
            chmod +x scripts/verify-pci-compliance-prod.sh
            scripts/verify-pci-compliance-prod.sh | tee prod-validation/pci-prod.txt
      - run:
          name: Test disaster recovery
          command: |
            chmod +x scripts/test-disaster-recovery.sh
            scripts/test-disaster-recovery.sh | tee prod-validation/dr.txt
      - store_artifacts:
          path: prod-validation
          destination: prod-validation

  rollback-production:
    executor: gcloud-executor
    environment:
      GCP_PROJECT_ID: << pipeline.parameters.gcp-project-id >>
      ENVIRONMENT: prod
    steps:
      - checkout
      - auth-gcp
      - run:
          name: Rollback to previous blue deployment
          command: |
            mkdir -p rollback
            chmod +x scripts/rollback.sh
            scripts/rollback.sh | tee rollback/rollback.txt
      - store_artifacts:
          path: rollback
          destination: rollback

workflows:
  payment-pipeline:
    jobs:
      - validate-python
      - validate-node
      - validate-infrastructure
      - scan-vulnerabilities:
          requires:
            - validate-python
            - validate-node
      - build-python-services:
          requires:
            - scan-vulnerabilities
            - validate-infrastructure
      - build-node-services:
          requires:
            - scan-vulnerabilities
            - validate-infrastructure
      - unit-test-python:
          requires:
            - build-python-services
          filters:
            branches:
              only: main
      - unit-test-node:
          requires:
            - build-node-services
          filters:
            branches:
              only: main
      - integration-test:
          requires:
            - unit-test-python
            - unit-test-node
      - security-sast:
          requires:
            - integration-test
      - security-secrets:
          requires:
            - integration-test
      - pci-compliance:
          requires:
            - security-sast
            - security-secrets
      - performance-test:
          requires:
            - pci-compliance
      - load-test-spanner:
          requires:
            - pci-compliance
      - deploy-dev:
          requires:
            - performance-test
            - load-test-spanner
          context:
            - gcp-dev
          filters:
            branches:
              only: main
      - smoke-test-dev:
          requires:
            - deploy-dev
      - deploy-staging-infrastructure:
          type: approval
          requires:
            - smoke-test-dev
      - deploy-staging-infrastructure:
          name: deploy-staging-infrastructure-run
          requires:
            - deploy-staging-infrastructure
          context:
            - gcp-staging
      - canary-staging:
          requires:
            - deploy-staging-infrastructure-run
      - integration-test-staging:
          requires:
            - canary-staging
      - e2e-pci-validation:
          requires:
            - integration-test-staging
      - dast-testing:
          requires:
            - integration-test-staging
      - compliance-validation:
          requires:
            - e2e-pci-validation
            - dast-testing
      - production-hold:
          type: approval
          requires:
            - compliance-validation
          filters:
            branches:
              only: main
      - blue-green-production:
          requires:
            - production-hold
          context:
            - gcp-prod
          filters:
            branches:
              only: main
      - smoke-test-production:
          requires:
            - blue-green-production
      - setup-monitoring:
          requires:
            - smoke-test-production
      - production-validation:
          requires:
            - setup-monitoring
