AWSTemplateFormatVersion: '2010-09-09'
Description: 'Secure event-driven data processing pipeline with S3, Lambda, DynamoDB, and Secrets Manager (Production, self-contained)'

Resources:
  # KMS Key for S3 Bucket Encryption
  ApplicationDataBucketKMSKey:
    Type: AWS::KMS::Key
    Properties:
      Description: 'KMS Key for ApplicationDataBucket encryption'
      KeyPolicy:
        Version: '2012-10-17'
        Statement:
          - Sid: Enable IAM User Permissions
            Effect: Allow
            Principal:
              AWS: !Sub 'arn:aws:iam::${AWS::AccountId}:root'
            Action: 'kms:*'
            Resource: '*'
          - Sid: Allow Lambda to decrypt
            Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action:
              - 'kms:Decrypt'
              - 'kms:DescribeKey'
            Resource: '*'
      Tags:
        - Key: Environment
          Value: Production

  # KMS Key Alias
  ApplicationDataBucketKMSKeyAlias:
    Type: AWS::KMS::Alias
    Properties:
      AliasName: alias/application-data-bucket-key
      TargetKeyId: !Ref ApplicationDataBucketKMSKey

  # S3 Bucket for Application Data
  ApplicationDataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub 'application-data-bucket-prod-001-${AWS::AccountId}-${AWS::Region}-tapstackpr1271'
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: aws:kms
              KMSMasterKeyID: !Ref ApplicationDataBucketKMSKey
            BucketKeyEnabled: true
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      Tags:
        - Key: Environment
          Value: production

  # DynamoDB Table for Processed Results
  ProcessedResultsDB:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: processedresultsdb
      AttributeDefinitions:
        - AttributeName: recordid
          AttributeType: S
      KeySchema:
        - AttributeName: recordid
          KeyType: HASH
      BillingMode: PAY_PER_REQUEST
      Tags:
        - Key: Environment
          Value: production

  # Secrets Manager Secret
  ApplicationSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: applicationsecret
      Description: 'secret for storing sensitive application data'
      SecretString: '{"apikey": "your-placeholder-api-key"}'
      Tags:
        - Key: Environment
          Value: production

  # IAM Role for Lambda Function
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3DataProcessorPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource: !Sub 'arn:aws:s3:::application-data-bucket-prod-001-${AWS::AccountId}-${AWS::Region}-tapstackpr1271/*'
              - Effect: Allow
                Action:
                  - dynamodb:PutItem
                Resource: !GetAtt ProcessedResultsDB.Arn
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub 'arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/S3DataProcessor:*'
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                Resource: !Ref ApplicationSecret
              - Effect: Allow
                Action:
                  - kms:Decrypt
                Resource: !GetAtt ApplicationDataBucketKMSKey.Arn
      Tags:
        - Key: Environment
          Value: production

  # MFA Enforcement Policy
  MFAEnforcementPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: 'policy that denies all actions if mfa is not present'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: DenyAllActionsWithoutMFA
            Effect: Deny
            Action: '*'
            Resource: '*'
            Condition:
              BoolIfExists:
                'aws:MultiFactorAuthPresent': 'false'

  # CloudWatch Log Group for Lambda
  LambdaLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: /aws/lambda/s3dataprocessor
      RetentionInDays: 14

  # Lambda Function for S3 Data Processing
  S3DataProcessor:
    Type: AWS::Lambda::Function
    DependsOn: LambdaLogGroup
    Properties:
      FunctionName: s3dataprocessor
      Runtime: python3.13
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Timeout: 60
      Environment:
        Variables:
          dynamodb_table: !Ref ProcessedResultsDB
          secret_name: !Ref ApplicationSecret
      Code:
        ZipFile: |
          import json
          import boto3
          import logging
          import os
          from urllib.parse import unquote_plus
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          s3_client = boto3.client('s3')
          dynamodb = boto3.resource('dynamodb')
          secrets_client = boto3.client('secretsmanager')
          def lambda_handler(event, context):
              try:
                  logger.info(f"Received event: {json.dumps(event)}")
                  for record in event['Records']:
                      bucket_name = record['s3']['bucket']['name']
                      object_key = unquote_plus(record['s3']['object']['key'])
                      logger.info(f"Processing object: {object_key} from bucket: {bucket_name}")
                      try:
                          secret_name = os.environ['secret_name']
                          secret_response = secrets_client.get_secret_value(SecretId=secret_name)
                          secret_data = json.loads(secret_response['SecretString'])
                          logger.info("Successfully retrieved secret from Secrets Manager")
                      except Exception as e:
                          logger.error(f"Error retrieving secret: {str(e)}")
                          raise
                      try:
                          s3_response = s3_client.head_object(Bucket=bucket_name, Key=object_key)
                          logger.info(f"S3 object metadata retrieved. Size: {s3_response.get('ContentLength', 'Unknown')}")
                      except Exception as e:
                          logger.error(f"Error accessing S3 object: {str(e)}")
                          raise
                      try:
                          table_name = os.environ['dynamodb_table']
                          table = dynamodb.Table(table_name)
                          item = {
                              'recordid': object_key,
                              'bucketname': bucket_name,
                              'processedat': context.aws_request_id,
                              'status': 'processed'
                          }
                          table.put_item(Item=item)
                          logger.info(f"Successfully wrote item to DynamoDB: {object_key}")
                      except Exception as e:
                          logger.error(f"Error writing to DynamoDB: {str(e)}")
                          raise
                  return {
                      'statusCode': 200,
                      'body': json.dumps('Successfully processed S3 event')
                  }
              except Exception as e:
                  logger.error(f"Error processing event: {str(e)}")
                  raise
      Tags:
        - Key: Environment
          Value: production

  # Permission for S3 to invoke Lambda
  LambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref S3DataProcessor
      Action: lambda:InvokeFunction
      Principal: s3.amazonaws.com
      SourceArn: !GetAtt ApplicationDataBucket.Arn
      SourceAccount: !Ref AWS::AccountId

Outputs:
  s3bucketname:
    description: 'name of the s3 bucket for application data'
    value: !Ref ApplicationDataBucket
    export:
      name: !Sub 'tapstackpr1271-s3bucketname'

  dynamodbtablename:
    description: 'name of the dynamodb table for processed results'
    value: !Ref ProcessedResultsDB
    export:
      name: !Sub 'tapstackpr1271-dynamodbtablename'

  lambdafunctionname:
    description: 'name of the lambda function'
    value: !Ref S3DataProcessor
    export:
      name: !Sub 'tapstackpr1271-lambdafunctionname'

  secretname:
    description: 'name of the secrets manager secret'
    value: !Ref ApplicationSecret
    export:
      name: !Sub 'tapstackpr1271-secretname'

  kmskeyid:
    description: 'id of the kms key used for s3 encryption'
    value: !Ref ApplicationDataBucketKMSKey
    export:
      name: !Sub 'tapstackpr1271-kmskeyid'

  mfaenforcementpolicyarn:
    description: 'arn of the mfa enforcement policy'
    value: !Ref MFAEnforcementPolicy
    export:
      name: !Sub 'tapstackpr1271-mfaenforcementpolicyarn'

# AWS CLI deployment command:
# aws cloudformation create-stack --stack-name secure-data-processing-pipeline --template-body file://secure_infrastructure.yaml --capabilities CAPABILITY_NAMED_IAM --region us-east-1