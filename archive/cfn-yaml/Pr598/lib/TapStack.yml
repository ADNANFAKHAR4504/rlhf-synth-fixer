AWSTemplateFormatVersion: '2010-09-09'
Description: 'Serverless application with Lambda, API Gateway, DynamoDB, and monitoring'

Parameters:
  Environment:
    Type: String
    AllowedValues:
      - dev
      - stage
      - prod
    Default: dev
    Description: 'Environment name'

  LogLevel:
    Type: String
    AllowedValues:
      - INFO
      - WARN
      - ERROR
    Default: INFO
    Description: 'Log level for Lambda function'

Resources:
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: DynamoDBAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:PutItem
                Resource: !GetAtt DataTable.Arn
        - PolicyName: CloudWatchLogs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub 'arn:aws:logs:us-east-1:${AWS::AccountId}:log-group:/aws/lambda/${Environment}-data-processor:*'

  LambdaLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/lambda/${Environment}-data-processor'
      RetentionInDays: 14

  DataProcessorFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${Environment}-data-processor'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          import logging
          from datetime import datetime
          import uuid

          log_level = os.environ.get('LOG_LEVEL', 'INFO')
          logger = logging.getLogger()
          logger.setLevel(getattr(logging, log_level))

          # Ensure boto3 client uses the correct region from environment variable
          dynamodb = boto3.resource('dynamodb', region_name=os.environ.get('REGION'))
          table_name = os.environ.get('TABLE_NAME')
          table = dynamodb.Table(table_name)

          def lambda_handler(event, context):
              try:
                  logger.info(f"Processing event: {json.dumps(event)}")
                  
                  if 'body' in event:
                      body = json.loads(event['body']) if isinstance(event['body'], str) else event['body']
                  else:
                      body = event
                  
                  item = {
                      'id': str(uuid.uuid4()),
                      'timestamp': datetime.utcnow().isoformat(),
                      'data': body,
                      'environment': os.environ.get('STAGE', 'dev')
                  }
                  
                  table.put_item(Item=item)
                  
                  logger.info(f"Successfully stored item with id: {item['id']}")
                  
                  return {
                      'statusCode': 200,
                      'headers': {
                          'Content-Type': 'application/json'
                      },
                      'body': json.dumps({
                          'message': 'Data processed successfully',
                          'id': item['id']
                      })
                  }
                  
              except Exception as e:
                  logger.error(f"Error processing data: {str(e)}")
                  return {
                      'statusCode': 500,
                      'headers': {
                          'Content-Type': 'application/json'
                      },
                      'body': json.dumps({
                          'error': 'Internal server error'
                      })
                  }
      Environment:
        Variables:
          STAGE: !Ref Environment
          LOG_LEVEL: !Ref LogLevel
          TABLE_NAME: !Ref DataTable
          REGION: us-east-1
      Timeout: 30
      MemorySize: 128

  LambdaApiGatewayPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref DataProcessorFunction
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub 'arn:aws:execute-api:us-east-1:${AWS::AccountId}:${DataApi}/*/*'

  DataApi:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: !Sub '${AWS::StackName}-data-api'
      Description: 'REST API for data processing'
      EndpointConfiguration:
        Types:
          - REGIONAL

  DataResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref DataApi
      ParentId: !GetAtt DataApi.RootResourceId
      PathPart: data

  DataMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref DataApi
      ResourceId: !Ref DataResource
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub 'arn:aws:apigateway:us-east-1:lambda:path/2015-03-31/functions/${DataProcessorFunction.Arn}/invocations'
      MethodResponses:
        - StatusCode: 200
          ResponseModels:
            application/json: Empty
        - StatusCode: 500
          ResponseModels:
            application/json: Empty

  ApiDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn: DataMethod
    Properties:
      RestApiId: !Ref DataApi
      StageName: !Ref Environment

  DataTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub '${Environment}-data-table'
      BillingMode: PROVISIONED
      AttributeDefinitions:
        - AttributeName: id
          AttributeType: S
      KeySchema:
        - AttributeName: id
          KeyType: HASH
      ProvisionedThroughput:
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5

  ApplicationAutoScalingDynamoDBRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: application-autoscaling.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess

  ReadCapacityScalableTarget:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    Properties:
      MaxCapacity: 20
      MinCapacity: 5
      ResourceId: !Sub 'table/${DataTable}'
      RoleARN: !GetAtt ApplicationAutoScalingDynamoDBRole.Arn
      ScalableDimension: dynamodb:table:ReadCapacityUnits
      ServiceNamespace: dynamodb

  WriteCapacityScalableTarget:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    Properties:
      MaxCapacity: 20
      MinCapacity: 5
      ResourceId: !Sub 'table/${DataTable}'
      RoleARN: !GetAtt ApplicationAutoScalingDynamoDBRole.Arn
      ScalableDimension: dynamodb:table:WriteCapacityUnits
      ServiceNamespace: dynamodb

  ReadScalingPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Properties:
      PolicyName: ReadAutoScalingPolicy
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref ReadCapacityScalableTarget
      TargetTrackingScalingPolicyConfiguration:
        TargetValue: 70.0
        ScaleInCooldown: 60
        ScaleOutCooldown: 60
        PredefinedMetricSpecification:
          PredefinedMetricType: DynamoDBReadCapacityUtilization

  WriteScalingPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Properties:
      PolicyName: WriteAutoScalingPolicy
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref WriteCapacityScalableTarget
      TargetTrackingScalingPolicyConfiguration:
        TargetValue: 70.0
        ScaleInCooldown: 60
        ScaleOutCooldown: 60
        PredefinedMetricSpecification:
          PredefinedMetricType: DynamoDBWriteCapacityUtilization
  # CloudWatch Alarm for Lambda Error Rate
  LambdaErrorAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${Environment}-lambda-error-rate-alarm'
      AlarmDescription: 'Alarm when Lambda error rate exceeds 5% for 5 minutes'
      ComparisonOperator: GreaterThanThreshold
      EvaluationPeriods: 1
      Threshold: 5.0
      TreatMissingData: notBreaching
      Metrics:
        - Id: e1
          Expression: '(m1/m2)*100'
          Label: 'Error Rate (%)'
        - Id: m1
          MetricStat:
            Metric:
              MetricName: Errors
              Namespace: AWS/Lambda
              Dimensions:
                - Name: FunctionName
                  Value: !Ref DataProcessorFunction
            Period: 300
            Stat: Sum
          ReturnData: false
        - Id: m2
          MetricStat:
            Metric:
              MetricName: Invocations
              Namespace: AWS/Lambda
              Dimensions:
                - Name: FunctionName
                  Value: !Ref DataProcessorFunction
            Period: 300
            Stat: Sum
          ReturnData: false

Outputs:
  ApiEndpoint:
    Description: 'API Gateway endpoint URL'
    Value: !Sub 'https://${DataApi}.execute-api.us-east-1.amazonaws.com/${Environment}/data'
    Export:
      Name: !Sub '${AWS::StackName}-ApiEndpoint'

  LambdaFunctionArn:
    Description: 'Lambda function ARN'
    Value: !GetAtt DataProcessorFunction.Arn
    Export:
      Name: !Sub '${AWS::StackName}-LambdaArn'

  DynamoDBTableName:
    Description: 'DynamoDB table name'
    Value: !Ref DataTable
    Export:
      Name: !Sub '${AWS::StackName}-TableName'

  DynamoDBTableArn:
    Description: 'DynamoDB table ARN'
    Value: !GetAtt DataTable.Arn
    Export:
      Name: !Sub '${AWS::StackName}-TableArn'
