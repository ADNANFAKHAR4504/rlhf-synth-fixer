# Model Failures

## 1. High availability architecture missing

Issue: The response deploys a single Lambda and API Gateway without redundancy mechanisms failing the "high availability" requirement.

**Original Code (Model Response):**

```python
# No high availability configuration
rest_api = apigateway.RestApi(
    f"{app_name}-api",
    name=f"{app_name}-api",
    description=f"API Gateway for {app_name}",
    endpoint_configuration={
        "types": "REGIONAL"  # Single region deployment
    }
)
```

**Working Solution:**

```python
# High availability with multi-AZ deployment and auto-scaling
class APIGatewayStack:
    def __init__(self, config: InfrastructureConfig):
        self.config = config
        # Enable high availability features
        self.enable_high_availability = config.enable_high_availability

    def _create_rest_api(self) -> apigateway.RestApi:
        return apigateway.RestApi(
            self.config.get_resource_name('api'),
            name=self.config.get_resource_name('api'),
            description=f"High availability API for {self.config.project_name}",
            endpoint_configuration={
                "types": "EDGE"  # Global edge deployment for HA
            },
            tags=self.config.tags
        )
```

---

## 2. Auto-scaling claim unsubstantiated

Issue: Lambda auto-scales automatically by default, but no API Gateway throttling/usage plan was set. The solution does not explicitly demonstrate or test scaling behavior.

**Original Code (Model Response):**

```python
# No usage plan or throttling configuration
deployment = apigateway.Deployment(
    f"{app_name}-deployment",
    rest_api=rest_api.id,
    opts=pulumi.ResourceOptions(depends_on=[get_integration, post_integration]),
    description=f"Deployment for {app_name}"
)
```

**Working Solution:**

```python
def _create_usage_plan(self) -> apigateway.UsagePlan:
    """Create usage plan with throttling for auto-scaling control."""
    return apigateway.UsagePlan(
        self.config.get_resource_name('usage-plan'),
        name=self.config.get_resource_name('usage-plan'),
        description="Usage plan with throttling for auto-scaling",
        api_stages=[{
            "api_id": self.rest_api.id,
            "stage": self.api_stage.stage_name,
        }],
        throttle_settings={
            "rate_limit": 1000,    # Requests per second
            "burst_limit": 2000,   # Burst capacity
        },
        quota_settings={
            "limit": 10000,        # Daily quota
            "period": "DAY",
        },
        tags=self.config.tags
    )
```

---

## 3. Logging to S3 not implemented

Issue: Prompt requires that all logs generated by Lambda and the application be stored in a versioned S3 bucket. The response creates CloudWatch Logs but no S3 bucket or log export configuration.

**Original Code (Model Response):**

```python
# Only CloudWatch logs, no S3 integration
def log_to_s3(event, context, response):
    """Log request and response to S3 bucket."""
    try:
        # This function exists but S3 bucket is not properly configured
        s3.put_object(
            Bucket=LOG_BUCKET,  # LOG_BUCKET not properly set up
            Key=key,
            Body=json.dumps(log_entry, default=str),
            ContentType='application/json'
        )
```

**Working Solution:**

```python
class S3Stack:
    def _create_logs_bucket(self) -> s3.Bucket:
        """Create versioned S3 bucket for log storage."""
        bucket = s3.Bucket(
            self.config.get_resource_name('logs'),
            versioning=s3.BucketVersioningArgs(enabled=True),
            server_side_encryption_configuration=s3.BucketServerSideEncryptionConfigurationArgs(
                rule=s3.BucketServerSideEncryptionConfigurationRuleArgs(
                    apply_server_side_encryption_by_default=s3.BucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefaultArgs(
                        sse_algorithm="AES256"
                    )
                )
            ),
            tags=self.config.tags
        )

        # Create log processor Lambda for S3 integration
        self._create_log_processor_function()
        return bucket
```

---

## 4. Versioning not enabled on any S3 bucket

Issue: The prompt explicitly demands versioned S3 buckets for logs, no bucket versioning configuration is included.

**Original Code (Model Response):**

```python
# S3 bucket without versioning
bucket = s3.Bucket(
    bucket_name,
    acl="private",
    # No versioning configuration
    server_side_encryption_configuration={
        "rule": {
            "applyServerSideEncryptionByDefault": {
                "sseAlgorithm": "AES256"
            }
        }
    }
)
```

**Working Solution:**

```python
def _create_logs_bucket(self) -> s3.Bucket:
    """Create versioned S3 bucket for log storage."""
    return s3.Bucket(
        self.config.get_resource_name('logs'),
        versioning=s3.BucketVersioningArgs(enabled=True),
        lifecycle_rules=[s3.BucketLifecycleRuleArgs(
            id="log-retention",
            enabled=True,
            expiration=s3.BucketLifecycleRuleExpirationArgs(days=90),
            noncurrent_version_expiration=s3.BucketLifecycleRuleNoncurrentVersionExpirationArgs(
                noncurrent_days=30
            )
        )],
        tags=self.config.tags
    )
```

---

## 5. CloudWatch monitoring incomplete

Issue: Only default logging is implied. No custom CloudWatch metrics, dashboards, or alarms for invocation.

**Original Code (Model Response):**

```python
# Basic monitoring without comprehensive metrics
dashboard = cloudwatch.Dashboard(
    f"{app_name}-dashboard",
    dashboard_name=f"{app_name}-dashboard",
    dashboard_body=pulumi.Output.all(
        lambda_functions["get"].name,
        lambda_functions["post"].name
    ).apply(lambda args: create_dashboard_body(app_name, args[0], args[1]))
)
```

**Working Solution:**

```python
class CloudWatchStack:
    def _create_alarms(self) -> Dict[str, cloudwatch.MetricAlarm]:
        """Create comprehensive CloudWatch alarms."""
        alarms = {}

        # Lambda error alarms
        error_alarm = cloudwatch.MetricAlarm(
            self.config.get_resource_name('lambda-error-alarm'),
            alarm_name=self.config.get_resource_name('lambda-error-alarm'),
            comparison_operator="GreaterThanThreshold",
            evaluation_periods=2,
            metric_name="Errors",
            namespace="AWS/Lambda",
            period=300,
            statistic="Sum",
            threshold=5,
            alarm_description="Lambda function errors",
            dimensions={"FunctionName": self.lambda_stack.get_main_function_name()},
            tags=self.config.tags
        )

        # API Gateway 4xx/5xx alarms
        api_error_alarm = cloudwatch.MetricAlarm(
            self.config.get_resource_name('api-error-alarm'),
            alarm_name=self.config.get_resource_name('api-error-alarm'),
            comparison_operator="GreaterThanThreshold",
            evaluation_periods=1,
            metric_name="4XXError",
            namespace="AWS/ApiGateway",
            period=300,
            statistic="Sum",
            threshold=10,
            alarm_description="API Gateway 4XX errors",
            dimensions={"ApiName": self.api_gateway_stack.get_rest_api_name()},
            tags=self.config.tags
        )

        return {"lambda_errors": error_alarm, "api_errors": api_error_alarm}
```

---

## 6. Region provider not enforced

Issue: The code does not instantiate an aws.Provider(region="us-east-1") or set Pulumi configuration for the region, so deployment may target the default account region incorrectly.

**Original Code (Model Response):**

```python
# No region enforcement
config = pulumi.Config()
app_name = config.get("appName") or "serverless-app"
region = "us-east-1"  # Hardcoded but not enforced
environment = config.get("environment") or "dev"
```

**Working Solution:**

```python
class InfrastructureConfig:
    def __init__(self, config: Optional[Dict] = None):
        """Initialize configuration with region enforcement."""
        self.config = config or {}

        # Enforce region configuration
        self.aws_region = os.getenv('AWS_REGION', 'us-east-1')
        self.environment = os.getenv('ENVIRONMENT', 'dev')
        self.project_name = os.getenv('PROJECT_NAME', 'serverless-app')

        # Create AWS provider with enforced region
        self.aws_provider = aws.Provider(
            "aws-provider",
            region=self.aws_region,
            default_tags=aws.ProviderDefaultTagsArgs(tags=self.tags)
        )
```

---

## 7. No documentation or inline comments explaining resources

Issue: Minimal or no comments accompany the Pulumi code, violating the "well-documented for maintainability" requirement.

** Original Code (Model Response):**

```python
# Minimal documentation
def create_lambda_functions(app_name, role, log_bucket, region):
    lambda_config = {
        "runtime": "python3.8",
        "role": role.arn,
        "environment": {
            "variables": {
                "LOG_BUCKET": log_bucket.id,
                "REGION": region,
                "APP_NAME": app_name
            }
        }
    }
```

**Working Solution:**

```python
class LambdaStack:
    """
    Lambda functions stack for serverless application.

    Creates Lambda functions with proper IAM roles, environment variables,
    and CloudWatch logging configuration for the serverless application.
    """

    def _create_main_function(self) -> lambda_.Function:
        """
        Create the main Lambda function for API requests.

        This function handles HTTP requests from API Gateway and processes
        them according to the application logic. It includes proper error
        handling, logging, and S3 integration for log storage.

        Returns:
            Lambda function resource
        """
        return lambda_.Function(
            self.config.get_resource_name('lambda-main'),
            name=self.config.get_resource_name('lambda-main'),
            description="Main Lambda function for serverless application API",
            runtime="python3.8",
            handler="index.lambda_handler",
            role=self.iam_stack.get_lambda_execution_role_arn(),
            code=pulumi.AssetArchive({
                ".": pulumi.FileArchive("./lambda")
            }),
            environment=lambda_.FunctionEnvironmentArgs(
                variables={
                    "ENVIRONMENT": self.config.environment,
                    "LOG_BUCKET": self.s3_stack.get_logs_bucket_name(),
                    "AWS_REGION": self.config.aws_region
                }
            ),
            timeout=30,
            memory_size=128,
            tags=self.config.tags
        )
```

---

## 8. S3 bucket for logs unused by Lambda

Issue: Even if a bucket is defined, the Lambda does not reference it for log delivery or export; logs only go to CloudWatch.

** Original Code (Model Response):**

```python
# Lambda doesn't actually use S3 for logs
def log_to_s3(event, context, response):
    """Log request and response to S3 bucket."""
    # This function exists but is not properly integrated
    s3.put_object(
        Bucket=LOG_BUCKET,  # Not properly configured
        Key=key,
        Body=json.dumps(log_entry, default=str)
    )
```

** Working Solution:**

```python
class LambdaStack:
    def _create_log_processor_function(self) -> lambda_.Function:
        """Create Lambda function for processing logs to S3."""
        return lambda_.Function(
            self.config.get_resource_name('lambda-log-processor'),
            name=self.config.get_resource_name('lambda-log-processor'),
            description="Processes CloudWatch logs and stores them in S3",
            runtime="python3.8",
            handler="log_processor.lambda_handler",
            role=self.iam_stack.get_log_processing_role_arn(),
            code=pulumi.AssetArchive({
                ".": pulumi.FileArchive("./lambda")
            }),
            environment=lambda_.FunctionEnvironmentArgs(
                variables={
                    "LOG_BUCKET": self.s3_stack.get_logs_bucket_name(),
                    "LOG_GROUP": f"/aws/lambda/{self.config.get_resource_name('lambda-main')}"
                }
            ),
            tags=self.config.tags
        )

    def _create_log_subscriptions(self) -> None:
        """Create CloudWatch log subscriptions for S3 export."""
        # Subscribe main Lambda logs to log processor
        logs.SubscriptionFilter(
            self.config.get_resource_name('log-subscription'),
            log_group=self.main_log_group.name,
            filter_pattern="",
            destination_arn=self.log_processor_function.arn,
            role_arn=self.iam_stack.get_log_processing_role_arn()
        )
```

---

## 9. Operational metrics absent

Issue: No setup for error/alarm thresholds or cloudwatch.MetricAlarm definitions â€” metrics are not actively monitored.

**Original Code (Model Response):**

```python
# Basic alarms without comprehensive monitoring
error_alarm = cloudwatch.MetricAlarm(
    f"{app_name}-{name}-errors-alarm",
    alarm_name=f"{app_name}-{name}-errors",
    comparison_operator="GreaterThanThreshold",
    evaluation_periods=1,
    metric_name="Errors",
    namespace="AWS/Lambda",
    period=60,
    statistic="Sum",
    threshold=2,
    alarm_description=f"Alarm when {name} function has errors"
)
```

**Working Solution:**

```python
class CloudWatchStack:
    def _create_operational_metrics(self) -> Dict[str, cloudwatch.MetricAlarm]:
        """Create comprehensive operational metrics and alarms."""
        alarms = {}

        # High error rate alarm
        error_rate_alarm = cloudwatch.MetricAlarm(
            self.config.get_resource_name('error-rate-alarm'),
            alarm_name=self.config.get_resource_name('error-rate-alarm'),
            comparison_operator="GreaterThanThreshold",
            evaluation_periods=2,
            metric_name="ErrorRate",
            namespace="AWS/Lambda",
            period=300,
            statistic="Average",
            threshold=0.1,  # 10% error rate
            alarm_description="High error rate detected",
            dimensions={"FunctionName": self.lambda_stack.get_main_function_name()},
            alarm_actions=[self.sns_topic.arn] if hasattr(self, 'sns_topic') else [],
            tags=self.config.tags
        )

        # Duration alarm
        duration_alarm = cloudwatch.MetricAlarm(
            self.config.get_resource_name('duration-alarm'),
            alarm_name=self.config.get_resource_name('duration-alarm'),
            comparison_operator="GreaterThanThreshold",
            evaluation_periods=1,
            metric_name="Duration",
            namespace="AWS/Lambda",
            period=300,
            statistic="Average",
            threshold=5000,  # 5 seconds
            alarm_description="High duration detected",
            dimensions={"FunctionName": self.lambda_stack.get_main_function_name()},
            tags=self.config.tags
        )

        return {"error_rate": error_rate_alarm, "duration": duration_alarm}
```

---

## 10. Security best practices incomplete

Issue: No encryption specified for S3, no explicit deny public access policy, and no KMS integration for data at rest or in transit.

**Original Code (Model Response):**

```python
# Basic S3 bucket without comprehensive security
bucket = s3.Bucket(
    bucket_name,
    acl="private",
    server_side_encryption_configuration={
        "rule": {
            "applyServerSideEncryptionByDefault": {
                "sseAlgorithm": "AES256"
            }
        }
    }
)
```

**Working Solution:**

```python
class S3Stack:
    def _create_logs_bucket(self) -> s3.Bucket:
        """Create secure, versioned S3 bucket for log storage."""
        bucket = s3.Bucket(
            self.config.get_resource_name('logs'),
            versioning=s3.BucketVersioningArgs(enabled=True),
            server_side_encryption_configuration=s3.BucketServerSideEncryptionConfigurationArgs(
                rule=s3.BucketServerSideEncryptionConfigurationRuleArgs(
                    apply_server_side_encryption_by_default=s3.BucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefaultArgs(
                        sse_algorithm="AES256"
                    )
                )
            ),
            tags=self.config.tags
        )

        # Block all public access
        s3.BucketPublicAccessBlock(
            self.config.get_resource_name('logs-access-block'),
            bucket=bucket.id,
            block_public_acls=True,
            block_public_policy=True,
            ignore_public_acls=True,
            restrict_public_buckets=True
        )

        # Bucket policy for least privilege access
        s3.BucketPolicy(
            self.config.get_resource_name('logs-policy'),
            bucket=bucket.id,
            policy=bucket.arn.apply(lambda arn: json.dumps({
                "Version": "2012-10-17",
                "Statement": [{
                    "Effect": "Deny",
                    "Principal": "*",
                    "Action": "s3:*",
                    "Resource": f"{arn}/*",
                    "Condition": {
                        "Bool": {"aws:SecureTransport": "false"}
                    }
                }]
            }))
        )

        return bucket
```

---

## 11. Code readability and structure

Issue: Variables are inlined with resource definitions, little to no abstraction or parameterization, which limits maintainability and reusability.

**Original Code (Model Response):**

```python
# Inline resource definitions without abstraction
get_handler = lambda_.Function(
    f"{app_name}-get-handler",
    name=f"{app_name}-get-handler",
    description="Handles GET requests for the serverless application",
    code=pulumi.AssetArchive({
        ".": pulumi.FileArchive("./lambda_functions/handlers")
    }),
    handler="handlers.get_handler",
    memory_size=256,
    timeout=30,
    **lambda_config
)
```

**Working Solution:**

```python
class InfrastructureConfig:
    """Centralized configuration management with proper abstraction."""

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.environment = os.getenv('ENVIRONMENT', 'dev')
        self.aws_region = os.getenv('AWS_REGION', 'us-east-1')
        self.project_name = os.getenv('PROJECT_NAME', 'serverless-app')
        self.name_prefix = f"{self.project_name}-{self.environment}"

    def get_resource_name(self, resource_type: str, suffix: str = '') -> str:
        """Generate consistent resource names."""
        name = f"{self.name_prefix}-{resource_type}"
        if suffix:
            name = f"{name}-{suffix}"
        return name

class LambdaStack:
    """Modular Lambda stack with proper abstraction."""

    def _create_main_function(self) -> lambda_.Function:
        """Create main Lambda function with proper configuration."""
        return lambda_.Function(
            self.config.get_resource_name('lambda-main'),
            name=self.config.get_resource_name('lambda-main'),
            description="Main Lambda function for serverless application",
            runtime=self.config.lambda_runtime,
            handler="index.lambda_handler",
            role=self.iam_stack.get_lambda_execution_role_arn(),
            code=self._get_lambda_code(),
            environment=self._get_environment_variables(),
            timeout=self.config.lambda_timeout,
            memory_size=self.config.lambda_memory,
            tags=self.config.tags
        )

    def _get_lambda_code(self) -> pulumi.AssetArchive:
        """Get Lambda function code archive."""
        return pulumi.AssetArchive({
            ".": pulumi.FileArchive("./lambda")
        })

    def _get_environment_variables(self) -> lambda_.FunctionEnvironmentArgs:
        """Get environment variables for Lambda function."""
        return lambda_.FunctionEnvironmentArgs(
            variables={
                "ENVIRONMENT": self.config.environment,
                "LOG_BUCKET": self.s3_stack.get_logs_bucket_name(),
                "AWS_REGION": self.config.aws_region
            }
        )
```
