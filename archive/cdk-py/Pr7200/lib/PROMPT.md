I’m working on a staging environment that was intentionally over-provisioned for Black Friday load testing, and now I need help turning the whole setup into clean CDK Python IaC while also preparing an automated optimization workflow. Even though the platform was sized for ~2M transactions per hour, the normal traffic pattern is closer to 200k/hour, with the database barely touching 50 active connections and the Redis cluster sitting at a 95% hit rate. The goal is to capture this current state in code, deploy it cleanly across regions, and then later right-size everything using a metrics-driven approach.

For the initial deployment in one region, I want CDK Python code (single file named as lib/tap_stack.py) that provisions a full VPC spread across three AZs with private subnets for the databases and Lambda access through NAT gateways. Inside this VPC, deploy a Multi-AZ RDS PostgreSQL instance (db.r6g.2xlarge, 1000 GB gp3, 10k IOPS, 6-hour backups, 30-day retention) along with a cross-AZ read replica. The compute tier runs on a c5.4xlarge Auto Scaling Group behind a Network Load Balancer, with capacity starting at 10 instances but able to scale down to 8 and up to 15. I also need a Redis cluster-mode ElastiCache deployment using r6g.2xlarge nodes (6 shards, 2 replicas each, encryption in transit, automatic failover) and five Lambda functions used for order workflows, each configured with 3008 MB of memory, 900-second timeouts, 100 reserved concurrency, and 50 units of provisioned concurrency. Please include CloudWatch Logs for all of these services, VPC endpoints for DynamoDB and S3, and security groups following least-privilege communication paths. The same IaC should be usable for a secondary region in another region, even if the primary work happens in a region.

Once the IaC portion is defined, I also need a companion optimize.py script built with boto3 that analyzes 45 days of CloudWatch metrics and produces right-sizing actions—using a very low confidence threshold (default 0.1 or 10%) to ensure recommendations are generated. The script should look at RDS utilization and scale down to r6g.xlarge if CPU and connections stay low, reclaim storage and IOPS if they're under-used, and even remove the read replica when lag and read throughput are negligible. EC2 should scale down to c5.2xlarge with reduced ASG capacity if p95 CPU stays low, while ElastiCache should shrink to 3 shards with 1 replica each when memory and throughput sit well below capacity. Lambda functions can drop to 1024 MB memory, shorter timeouts, and reduced concurrency if the p95 durations remain low and cold starts are rare. Any changes to the database must follow a blue-green strategy with automatic rollback if connection errors exceed 1%.

The optimization script should also generate both CSV and JSON reports summarizing every recommendation, using Reserved Instance pricing to calculate savings. The CSV should include fields like the current and proposed configuration, p50/p95/p99 utilization, hourly and annual cost comparisons, confidence scores, and any notes about the decision. Please make sure the script excludes resources tagged CriticalPath: true. This entire flow should feel cohesive and production-ready—CDK code for the infrastructure, a metrics-driven optimization tool, and reporting outputs that are safe enough for a staging account operating across multiple regions.
